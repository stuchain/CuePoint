# Implementation Step 1.9: Operational Requirements

## Implementation Overview
**What We're Building**: Operational infrastructure including standard storage paths, logging system, network reliability, data retention policies, and diagnostic capabilities.

## Implementation Tasks

### Task 1.9.1: Implement Storage Locations

**What to Build**
- Standard paths utility using QStandardPaths
- Path initialization and creation
- Path validation

**Implementation Details**

**1.9.1.1 Standard Paths Utility**
- **File to Create**: `SRC/cuepoint/utils/paths.py`
- **Implementation**:
  ```python
  """Standard application paths using QStandardPaths"""
  from pathlib import Path
  from PySide6.QtCore import QStandardPaths
  from cuepoint.utils.platform import is_macos, is_windows
  import os
    
  class AppPaths:
      """Standard application paths"""
      
      @staticmethod
      def _ensure_dir(path: Path) -> Path:
          """Ensure directory exists"""
          path.mkdir(parents=True, exist_ok=True)
          return path
      
      @staticmethod
      def config_dir() -> Path:
          """Configuration directory"""
          if is_macos():
              base = Path.home() / "Library" / "Application Support" / "CuePoint"
          elif is_windows():
              base = Path(os.getenv("APPDATA", "")) / "CuePoint"
          else:
              base = Path(QStandardPaths.writableLocation(
                  QStandardPaths.AppConfigLocation
              )) / "CuePoint"
          return AppPaths._ensure_dir(base / "config")
      
      @staticmethod
      def data_dir() -> Path:
          """Application data directory"""
          if is_macos():
              return AppPaths._ensure_dir(
                  Path.home() / "Library" / "Application Support" / "CuePoint"
              )
          elif is_windows():
              return AppPaths._ensure_dir(
                  Path(os.getenv("LOCALAPPDATA", "")) / "CuePoint"
              )
          else:
              return AppPaths._ensure_dir(Path(
                  QStandardPaths.writableLocation(QStandardPaths.AppLocalDataLocation)
              ) / "CuePoint")
      
      @staticmethod
      def cache_dir() -> Path:
          """Cache directory"""
          if is_macos():
              return AppPaths._ensure_dir(
                  Path.home() / "Library" / "Caches" / "CuePoint"
              )
          elif is_windows():
              return AppPaths._ensure_dir(
                  Path(os.getenv("LOCALAPPDATA", "")) / "CuePoint" / "Cache"
              )
          else:
              return AppPaths._ensure_dir(Path(
                  QStandardPaths.writableLocation(QStandardPaths.CacheLocation)
              ) / "CuePoint")
      
      @staticmethod
      def logs_dir() -> Path:
          """Logs directory"""
          if is_macos():
              return AppPaths._ensure_dir(
                  Path.home() / "Library" / "Logs" / "CuePoint"
              )
          elif is_windows():
              return AppPaths._ensure_dir(
                  Path(os.getenv("LOCALAPPDATA", "")) / "CuePoint" / "Logs"
              )
          else:
              return AppPaths._ensure_dir(
                  AppPaths.data_dir() / "Logs"
              )
      
      @staticmethod
      def exports_dir() -> Path:
          """Default exports directory"""
          if is_macos():
              return AppPaths._ensure_dir(
                  Path.home() / "Documents" / "CuePoint"
              )
          elif is_windows():
              return AppPaths._ensure_dir(
                  Path(os.getenv("USERPROFILE", "")) / "Documents" / "CuePoint"
              )
          else:
              return AppPaths._ensure_dir(Path(
                  QStandardPaths.writableLocation(QStandardPaths.DocumentsLocation)
              ) / "CuePoint")
  ```
- **Purpose**: Consistent paths across OS
- **Usage**: Import and use throughout app

**1.9.1.2 Path Initialization**
- **File to Modify**: `SRC/cuepoint/__init__.py`
- **Implementation**:
  ```python
  """Initialize application paths on import"""
  from cuepoint.utils.paths import AppPaths
    
  # Initialize all standard paths
  AppPaths.config_dir()
  AppPaths.data_dir()
  AppPaths.cache_dir()
  AppPaths.logs_dir()
  AppPaths.exports_dir()
  ```
- **Purpose**: Ensure paths exist at startup
- **Integration**: Called on app initialization

### Task 1.9.2: Implement Logging Requirements

**What to Build**
- Rotating file logger
- Crash log capture
- Log viewer UI
- Log cleanup

**Implementation Details**

**1.9.2.1 Rotating File Logger**
- **File to Create**: `SRC/cuepoint/utils/logger.py`
- **Implementation**:
  ```python
  """Rotating file logger with crash capture"""
  import logging
  import logging.handlers
  from pathlib import Path
  from cuepoint.utils.paths import AppPaths
  from cuepoint.version import get_version_string
  import sys
  import traceback
    
  class RotatingFileHandler(logging.handlers.RotatingFileHandler):
      """Rotating file handler with size and count limits"""
      def __init__(self, filename, max_bytes=5*1024*1024, backup_count=5):
          log_dir = AppPaths.logs_dir()
          log_file = log_dir / filename
          super().__init__(str(log_file), maxBytes=max_bytes, backupCount=backup_count)
    
  def setup_logging(debug=False):
      """Setup application logging"""
      log_level = logging.DEBUG if debug else logging.INFO
      
      # Create formatter
      formatter = logging.Formatter(
          '%(asctime)s [%(levelname)s] [v{}] %(name)s: %(message)s'.format(
              get_version_string()
          ),
          datefmt='%Y-%m-%d %H:%M:%S'
      )
      
      # File handler (rotating)
      file_handler = RotatingFileHandler('cuepoint.log')
      file_handler.setLevel(log_level)
      file_handler.setFormatter(formatter)
      
      # Console handler (dev only)
      if debug:
          console_handler = logging.StreamHandler(sys.stdout)
          console_handler.setLevel(log_level)
          console_handler.setFormatter(formatter)
          logging.getLogger().addHandler(console_handler)
      
      # Root logger
      root_logger = logging.getLogger()
      root_logger.setLevel(log_level)
      root_logger.addHandler(file_handler)
      
      # Exception handler
      def exception_handler(exc_type, exc_value, exc_traceback):
          """Global exception handler"""
          if issubclass(exc_type, KeyboardInterrupt):
              sys.__excepthook__(exc_type, exc_value, exc_traceback)
              return
          
          # Log exception
          logging.critical(
              "Uncaught exception",
              exc_info=(exc_type, exc_value, exc_traceback)
          )
          
          # Write crash log
          crash_log = AppPaths.logs_dir() / f"crash-{datetime.now().strftime('%Y%m%d-%H%M%S')}.log"
          with open(crash_log, 'w') as f:
              f.write(f"Crash at {datetime.now()}\n")
              f.write(f"Version: {get_version_string()}\n")
              f.write("".join(traceback.format_exception(exc_type, exc_value, exc_traceback)))
      
      sys.excepthook = exception_handler
  ```
- **Purpose**: Comprehensive logging with rotation
- **Usage**: Call at app startup

**1.9.2.2 Log Viewer UI**
- **File to Create**: `SRC/cuepoint/ui/widgets/log_viewer.py`
- **Implementation**:
  ```python
  class LogViewer(QDialog):
      """Log viewer dialog"""
      def __init__(self, parent=None):
          super().__init__(parent)
          self.setWindowTitle("Log Viewer")
          
          layout = QVBoxLayout()
          
          # Log text area
          self.log_text = QTextEdit()
          self.log_text.setReadOnly(True)
          self.log_text.setFont(QFont("Courier", 10))
          layout.addWidget(self.log_text)
          
          # Load logs
          self.load_logs()
          
          # Buttons
          button_layout = QHBoxLayout()
          refresh_btn = QPushButton("Refresh")
          refresh_btn.clicked.connect(self.load_logs)
          open_folder_btn = QPushButton("Open Logs Folder")
          open_folder_btn.clicked.connect(self.open_logs_folder)
          button_layout.addWidget(refresh_btn)
          button_layout.addWidget(open_folder_btn)
          layout.addLayout(button_layout)
          
          self.setLayout(layout)
      
      def load_logs(self):
          """Load log files"""
          log_file = AppPaths.logs_dir() / "cuepoint.log"
          if log_file.exists():
              self.log_text.setPlainText(log_file.read_text())
  ```
- **Purpose**: View logs in-app
- **Integration**: Help menu → View Logs

### Task 1.9.3: Implement Network Behavior

**What to Build**
- Network client with timeouts
- Retry logic with backoff
- Offline handling
- Rate limiting

**Implementation Details**

**1.9.3.1 Network Client with Timeouts**
- **File to Modify**: `SRC/cuepoint/core/scraper.py`
- **Implementation**:
  ```python
  import requests
  from requests.adapters import HTTPAdapter
  from urllib3.util.retry import Retry
    
  class NetworkClient:
      """Network client with timeouts and retries"""
      def __init__(self):
          self.session = requests.Session()
          
          # Retry strategy
          retry_strategy = Retry(
              total=3,
              backoff_factor=0.5,
              status_forcelist=[429, 500, 502, 503, 504],
              allowed_methods=["GET", "POST"]
          )
          
          adapter = HTTPAdapter(max_retries=retry_strategy)
          self.session.mount("http://", adapter)
          self.session.mount("https://", adapter)
      
      def get(self, url, timeout=(5, 30)):
          """GET request with timeout"""
          try:
              response = self.session.get(url, timeout=timeout)
              return response
          except requests.exceptions.Timeout:
              raise NetworkTimeoutError(f"Request timed out: {url}")
          except requests.exceptions.ConnectionError:
              raise NetworkConnectionError(f"Connection failed: {url}")
  ```
- **Purpose**: Reliable network operations
- **Integration**: Used by scraper service

**1.9.3.2 Offline Handling**
- **File to Modify**: `SRC/cuepoint/core/scraper.py`
- **Implementation**:
  ```python
  def check_network_available() -> bool:
      """Check if network is available"""
      try:
          response = requests.get("https://www.google.com", timeout=5)
          return response.status_code == 200
      except:
          return False
    
  def scrape_with_offline_handling(self, url):
      """Scrape with offline handling"""
      if not check_network_available():
          raise NetworkUnavailableError("Network unavailable. Please check your connection.")
      
      # Try cache first
      cached = self.cache.get(url)
      if cached:
          return cached
      
      # Network request
      return self.network_client.get(url)
  ```
- **Purpose**: Graceful offline behavior
- **Integration**: Scraper service

### Task 1.9.4: Implement Data Retention

**What to Build**
- Cache management
- History retention
- Data cleanup utilities

**Implementation Details**

**1.9.4.1 Cache Management**
- **File to Create**: `SRC/cuepoint/utils/cache_manager.py`
- **Implementation**:
  ```python
  """Cache management with size limits"""
  from pathlib import Path
  from cuepoint.utils.paths import AppPaths
  import shutil
  from datetime import datetime, timedelta
    
  class CacheManager:
      """Manage application cache"""
      
      @staticmethod
      def get_cache_size() -> int:
          """Get total cache size in bytes"""
          cache_dir = AppPaths.cache_dir()
          total = 0
          for file in cache_dir.rglob("*"):
              if file.is_file():
                  total += file.stat().st_size
          return total
      
      @staticmethod
      def clear_cache():
          """Clear all cache"""
          cache_dir = AppPaths.cache_dir()
          for item in cache_dir.iterdir():
              if item.is_file():
                  item.unlink()
              elif item.is_dir():
                  shutil.rmtree(item)
      
      @staticmethod
      def prune_cache(max_size_mb: int = 500, max_age_days: int = 7):
          """Prune cache to size and age limits"""
          cache_dir = AppPaths.cache_dir()
          max_size_bytes = max_size_mb * 1024 * 1024
          max_age = timedelta(days=max_age_days)
          
          # Get all cache files with age
          files = []
          for file in cache_dir.rglob("*"):
              if file.is_file():
                age = datetime.now() - datetime.fromtimestamp(file.stat().st_mtime)
                files.append((file, file.stat().st_size, age))
          
          # Sort by age (oldest first)
          files.sort(key=lambda x: x[2])
          
          # Remove old files
          current_size = sum(f[1] for f in files)
          for file, size, age in files:
              if age > max_age:
                  file.unlink()
                  current_size -= size
              elif current_size > max_size_bytes:
                  file.unlink()
                  current_size -= size
              else:
                  break
  ```
- **Purpose**: Manage cache size and age
- **Integration**: Settings UI, startup cleanup

**1.9.4.2 History Retention**
- **File to Create**: `SRC/cuepoint/utils/history_manager.py`
- **Implementation**:
  ```python
  """History file management"""
  from pathlib import Path
  from cuepoint.utils.paths import AppPaths
  from datetime import datetime, timedelta
    
  class HistoryManager:
      """Manage past search history"""
      
      @staticmethod
      def get_recent_files(max_files: int = 10, max_days: int = 30) -> List[Path]:
          """Get recent CSV files"""
          exports_dir = AppPaths.exports_dir()
          cutoff_date = datetime.now() - timedelta(days=max_days)
          
          files = []
          for file in exports_dir.glob("*.csv"):
              mtime = datetime.fromtimestamp(file.stat().st_mtime)
              if mtime > cutoff_date:
                  files.append((file, mtime))
          
          # Sort by modification time (newest first)
          files.sort(key=lambda x: x[1], reverse=True)
          
          # Return up to max_files
          return [f[0] for f in files[:max_files]]
      
      @staticmethod
      def cleanup_old_files(max_days: int = 30):
          """Clean up old history files (optional, user-controlled)"""
          # Only if user explicitly enables
          pass
  ```
- **Purpose**: Manage history file retention
- **Integration**: Past Searches view

### Task 1.9.5: Implement Diagnostics

**What to Build**
- Diagnostic collection service
- Support bundle generator
- Diagnostic export UI

**Implementation Details**

**1.9.5.1 Diagnostic Collection**
- **File to Create**: `SRC/cuepoint/utils/diagnostics.py`
- **Implementation**:
  ```python
  """Diagnostic information collection"""
  import platform
  import json
  from pathlib import Path
  from cuepoint.utils.paths import AppPaths
  from cuepoint.version import get_build_info
  from PySide6.QtCore import QSettings
    
  def collect_diagnostics() -> dict:
      """Collect diagnostic information"""
      build_info = get_build_info()
      
      diagnostics = {
          "app_version": build_info["version"],
          "build_number": build_info.get("build_number"),
          "commit_sha": build_info.get("commit_sha"),
          "platform": platform.system(),
          "platform_version": platform.version(),
          "architecture": platform.machine(),
          "python_version": platform.python_version(),
      }
      
      # Settings (non-sensitive)
      settings = QSettings()
      diagnostics["settings"] = {
          "output_directory": settings.value("output_directory", ""),
          "cache_enabled": settings.value("cache_enabled", True),
          # ... other non-sensitive settings
      }
      
      # Recent log lines
      log_file = AppPaths.logs_dir() / "cuepoint.log"
      if log_file.exists():
          lines = log_file.read_text().splitlines()
          diagnostics["recent_logs"] = lines[-200:]  # Last 200 lines
      
      # Crash logs
      crash_logs = list(AppPaths.logs_dir().glob("crash-*.log"))
      if crash_logs:
          latest_crash = max(crash_logs, key=lambda p: p.stat().st_mtime)
          diagnostics["latest_crash"] = latest_crash.read_text()
      
      return diagnostics
  ```
- **Purpose**: Collect diagnostic information
- **Usage**: Support bundle generation

**1.9.5.2 Support Bundle Generator**
- **File to Create**: `SRC/cuepoint/utils/support_bundle.py`
- **Implementation**:
  ```python
  """Generate support bundle for diagnostics"""
  import zipfile
  import json
  from pathlib import Path
  from datetime import datetime
  from cuepoint.utils.paths import AppPaths
  from cuepoint.utils.diagnostics import collect_diagnostics
    
  def generate_support_bundle(output_path: Path) -> Path:
      """Generate support bundle ZIP file"""
      bundle_path = output_path / f"cuepoint-support-{datetime.now().strftime('%Y%m%d-%H%M%S')}.zip"
      
      with zipfile.ZipFile(bundle_path, 'w', zipfile.ZIP_DEFLATED) as zipf:
          # Diagnostics JSON
          diagnostics = collect_diagnostics()
          zipf.writestr("diagnostics.json", json.dumps(diagnostics, indent=2))
          
          # Log files
          log_dir = AppPaths.logs_dir()
          for log_file in log_dir.glob("*.log*"):
              zipf.write(log_file, f"logs/{log_file.name}")
          
          # Crash logs
          for crash_file in log_dir.glob("crash-*.log"):
              zipf.write(crash_file, f"crashes/{crash_file.name}")
      
      return bundle_path
  ```
- **Purpose**: Create support bundle for bug reports
- **Integration**: Help menu → Export Support Bundle

**1.9.5.3 Diagnostic Export UI**
- **File to Modify**: `SRC/cuepoint/ui/main_window.py`
- **Implementation**:
  ```python
  from cuepoint.utils.support_bundle import generate_support_bundle
  from cuepoint.utils.paths import AppPaths
    
  def export_support_bundle(self):
      """Export support bundle"""
      output_dir = QFileDialog.getExistingDirectory(
          self, "Select folder to save support bundle", str(AppPaths.exports_dir())
      )
      if not output_dir:
          return
      
      bundle_path = generate_support_bundle(Path(output_dir))
      
      QMessageBox.information(
          self,
          "Support Bundle Created",
          f"Support bundle created:\n{bundle_path}\n\n"
          "Please attach this file when reporting issues."
      )
  ```
- **Purpose**: Easy support bundle export
- **Integration**: Help menu

## Implementation Checklist

### Storage
- [ ] Create standard paths utility
- [ ] Initialize paths on startup
- [ ] Test paths on both platforms

### Logging
- [ ] Create rotating file logger
- [ ] Implement crash log capture
- [ ] Create log viewer UI
- [ ] Test log rotation

### Network
- [ ] Enhance network client with timeouts
- [ ] Implement retry logic
- [ ] Add offline handling
- [ ] Test network reliability

### Data Retention
- [ ] Create cache manager
- [ ] Create history manager
- [ ] Add cleanup utilities
- [ ] Test data retention

### Diagnostics
- [ ] Create diagnostic collection
- [ ] Create support bundle generator
- [ ] Add diagnostic export UI
- [ ] Test support bundle generation

## Files to Create/Modify

### New Files
1. `SRC/cuepoint/utils/paths.py` - Standard paths
2. `SRC/cuepoint/utils/logger.py` - Logging system
3. `SRC/cuepoint/ui/widgets/log_viewer.py` - Log viewer
4. `SRC/cuepoint/utils/cache_manager.py` - Cache management
5. `SRC/cuepoint/utils/history_manager.py` - History management
6. `SRC/cuepoint/utils/diagnostics.py` - Diagnostic collection
7. `SRC/cuepoint/utils/support_bundle.py` - Support bundle generation

### Files to Modify
1. `SRC/cuepoint/__init__.py` - Path initialization
2. `SRC/cuepoint/core/scraper.py` - Network client enhancements
3. `SRC/cuepoint/ui/main_window.py` - Diagnostic export UI

## Implementation Dependencies

### Prerequisites
- Step 1.4: Target outcomes (defines operational requirements)
- Step 1.5: Supported platforms (defines path requirements)
- Step 1.7: Versioning (provides version info for diagnostics)

### Enables
- Step 6: Runtime operational design (implements these requirements)
- Step 9.5: Support UX (uses diagnostics)

## Success Criteria

### Storage
- ✅ Paths consistent across OS
- ✅ Paths initialized on startup
- ✅ All paths writable

### Logging
- ✅ Logs rotate at 5MB
- ✅ Crash logs captured
- ✅ Log viewer functional

### Network
- ✅ Timeouts configured
- ✅ Retry logic works
- ✅ Offline handling graceful

### Diagnostics
- ✅ Diagnostic collection complete
- ✅ Support bundle generation works
- ✅ Bundle includes all necessary info

## Next Implementation Steps

After completing Step 1.9:
1. **Step 6**: Runtime operational design (implements these in detail)
2. **Step 9.5**: Support UX (uses diagnostics)

## Detailed Operational Implementation

### Storage Locations - Complete Implementation

**1.9.1.3 Enhanced Paths Utility with Validation**
- **Complete Paths Module with Error Handling**:
  ```python
  # SRC/cuepoint/utils/paths.py (complete implementation)
  """Standard application paths using QStandardPaths with validation"""
  from pathlib import Path
  from PySide6.QtCore import QStandardPaths
  from cuepoint.utils.platform import is_macos, is_windows
  import os
  import logging
  
  logger = logging.getLogger(__name__)
  
  class AppPaths:
      """Standard application paths with platform-specific handling"""
      
      _initialized = False
      
      @staticmethod
      def _ensure_dir(path: Path) -> Path:
          """Ensure directory exists, create if needed"""
          try:
              path.mkdir(parents=True, exist_ok=True)
              return path
          except PermissionError as e:
              logger.error(f"Permission denied creating directory {path}: {e}")
              raise
          except Exception as e:
              logger.error(f"Error creating directory {path}: {e}")
              raise
      
      @staticmethod
      def _validate_path(path: Path) -> bool:
          """Validate path is accessible"""
          try:
              # Check if parent is writable
              if path.exists():
                  return os.access(path, os.W_OK)
              else:
                  return os.access(path.parent, os.W_OK)
          except Exception:
              return False
      
      @staticmethod
      def config_dir() -> Path:
          """Configuration directory"""
          if is_macos():
              base = Path.home() / "Library" / "Application Support" / "CuePoint"
          elif is_windows():
              appdata = os.getenv("APPDATA")
              if not appdata:
                  raise RuntimeError("APPDATA environment variable not set")
              base = Path(appdata) / "CuePoint"
          else:
              base = Path(QStandardPaths.writableLocation(
                  QStandardPaths.AppConfigLocation
              )) / "CuePoint"
          
          config_path = base / "config"
          return AppPaths._ensure_dir(config_path)
      
      @staticmethod
      def config_file() -> Path:
          """Main configuration file"""
          return AppPaths.config_dir() / "config.yaml"
      
      @staticmethod
      def data_dir() -> Path:
          """Application data directory"""
          if is_macos():
              path = Path.home() / "Library" / "Application Support" / "CuePoint"
          elif is_windows():
              localappdata = os.getenv("LOCALAPPDATA")
              if not localappdata:
                  raise RuntimeError("LOCALAPPDATA environment variable not set")
              path = Path(localappdata) / "CuePoint"
          else:
              path = Path(QStandardPaths.writableLocation(
                  QStandardPaths.AppLocalDataLocation
              )) / "CuePoint"
          
          return AppPaths._ensure_dir(path)
      
      @staticmethod
      def cache_dir() -> Path:
          """Cache directory"""
          if is_macos():
              path = Path.home() / "Library" / "Caches" / "CuePoint"
          elif is_windows():
              localappdata = os.getenv("LOCALAPPDATA")
              if not localappdata:
                  raise RuntimeError("LOCALAPPDATA environment variable not set")
              path = Path(localappdata) / "CuePoint" / "Cache"
          else:
              path = Path(QStandardPaths.writableLocation(
                  QStandardPaths.CacheLocation
              )) / "CuePoint"
          
          return AppPaths._ensure_dir(path)
      
      @staticmethod
      def logs_dir() -> Path:
          """Logs directory"""
          if is_macos():
              path = Path.home() / "Library" / "Logs" / "CuePoint"
          elif is_windows():
              localappdata = os.getenv("LOCALAPPDATA")
              if not localappdata:
                  raise RuntimeError("LOCALAPPDATA environment variable not set")
              path = Path(localappdata) / "CuePoint" / "Logs"
          else:
              path = AppPaths.data_dir() / "Logs"
          
          return AppPaths._ensure_dir(path)
      
      @staticmethod
      def exports_dir() -> Path:
          """Default exports directory"""
          if is_macos():
              downloads = Path.home() / "Downloads"
          elif is_windows():
              downloads = Path.home() / "Downloads"
          else:
              downloads = Path(QStandardPaths.writableLocation(
                  QStandardPaths.DownloadLocation
              ))
          
          exports = downloads / "CuePoint Exports"
          return AppPaths._ensure_dir(exports)
      
      @staticmethod
      def temp_dir() -> Path:
          """Temporary files directory"""
          path = AppPaths.cache_dir() / "temp"
          return AppPaths._ensure_dir(path)
      
      @staticmethod
      def app_dir() -> Path:
          """Application installation directory"""
          import sys
          if getattr(sys, 'frozen', False):
              # Running as bundled app
              if is_macos():
                  # macOS: Get app bundle path
                  return Path(sys.executable).parent.parent.parent
              else:
                  # Windows: Get executable directory
                  return Path(sys.executable).parent
          else:
              # Running from source
              return Path(__file__).parent.parent.parent
      
      @staticmethod
      def initialize_all():
          """Initialize all standard paths"""
          if AppPaths._initialized:
              return
            
          try:
              AppPaths.config_dir()
              AppPaths.data_dir()
              AppPaths.cache_dir()
              AppPaths.logs_dir()
              AppPaths.exports_dir()
              AppPaths.temp_dir()
              AppPaths._initialized = True
              logger.info("Application paths initialized successfully")
          except Exception as e:
              logger.error(f"Failed to initialize application paths: {e}")
              raise
      
      @staticmethod
      def get_all_paths() -> dict:
          """Get all paths for diagnostics"""
          return {
              "config": str(AppPaths.config_dir()),
              "data": str(AppPaths.data_dir()),
              "cache": str(AppPaths.cache_dir()),
              "logs": str(AppPaths.logs_dir()),
              "exports": str(AppPaths.exports_dir()),
              "temp": str(AppPaths.temp_dir()),
              "app": str(AppPaths.app_dir()),
          }
  ```

### Logging Requirements - Complete Implementation

**1.9.2.3 Enhanced Logging System**
- **Complete Logging Implementation**:
  ```python
  # SRC/cuepoint/utils/logger.py
  """Comprehensive logging system with rotation and crash capture"""
  import logging
  import logging.handlers
  import sys
  import traceback
  from pathlib import Path
  from datetime import datetime
  from cuepoint.utils.paths import AppPaths
  from cuepoint.version import get_version_string, get_build_info
  
  logger = logging.getLogger(__name__)
  
  class RotatingFileHandler(logging.handlers.RotatingFileHandler):
      """Rotating file handler with size and count limits"""
      def __init__(self, filename: str, max_bytes: int = 5*1024*1024, backup_count: int = 5):
          log_dir = AppPaths.logs_dir()
          log_file = log_dir / filename
          super().__init__(
              str(log_file),
              maxBytes=max_bytes,
              backupCount=backup_count,
              encoding='utf-8'
          )
  
  def setup_logging(debug: bool = False, log_level: str = None):
      """Setup application logging"""
      # Determine log level
      if log_level:
          level = getattr(logging, log_level.upper(), logging.INFO)
      else:
          level = logging.DEBUG if debug else logging.INFO
      
      # Get version info
      version = get_version_string()
      build_info = get_build_info()
      
      # Create formatter
      formatter = logging.Formatter(
          '%(asctime)s [%(levelname)s] [v{}] [%(name)s] %(message)s'.format(version),
          datefmt='%Y-%m-%d %H:%M:%S'
      )
      
      # File handler (rotating)
      file_handler = RotatingFileHandler('cuepoint.log', max_bytes=5*1024*1024, backup_count=5)
      file_handler.setLevel(level)
      file_handler.setFormatter(formatter)
      
      # Console handler (dev only or if debug)
      if debug or not getattr(sys, 'frozen', False):
          console_handler = logging.StreamHandler(sys.stdout)
          console_handler.setLevel(level)
          console_handler.setFormatter(formatter)
          logging.getLogger().addHandler(console_handler)
      
      # Root logger
      root_logger = logging.getLogger()
      root_logger.setLevel(level)
      root_logger.addHandler(file_handler)
      
      # Log startup information
      root_logger.info("=" * 60)
      root_logger.info(f"CuePoint starting - Version: {version}")
      if build_info.get("build_number"):
          root_logger.info(f"Build: {build_info['build_number']}")
      if build_info.get("commit_sha"):
          root_logger.info(f"Commit: {build_info['commit_sha'][:8]}")
      root_logger.info(f"Log level: {logging.getLevelName(level)}")
      root_logger.info("=" * 60)
      
      # Set up exception handler
      def exception_handler(exc_type, exc_value, exc_traceback):
          """Global exception handler for uncaught exceptions"""
          if issubclass(exc_type, KeyboardInterrupt):
              sys.__excepthook__(exc_type, exc_value, exc_traceback)
              return
          
          # Log exception
          root_logger.critical(
              "Uncaught exception",
              exc_info=(exc_type, exc_value, exc_traceback)
          )
          
          # Write crash log
          try:
              crash_log = AppPaths.logs_dir() / f"crash-{datetime.now().strftime('%Y%m%d-%H%M%S')}.log"
              with open(crash_log, 'w', encoding='utf-8') as f:
                  f.write(f"Crash at {datetime.now().isoformat()}\n")
                  f.write(f"Version: {version}\n")
                  if build_info.get("build_number"):
                      f.write(f"Build: {build_info['build_number']}\n")
                  if build_info.get("commit_sha"):
                      f.write(f"Commit: {build_info['commit_sha']}\n")
                  f.write("\n" + "=" * 60 + "\n")
                  f.write("".join(traceback.format_exception(exc_type, exc_value, exc_traceback)))
              root_logger.info(f"Crash log written to: {crash_log}")
          except Exception as e:
              root_logger.error(f"Failed to write crash log: {e}")
      
      sys.excepthook = exception_handler
      
      return root_logger
  ```

**1.9.2.4 Enhanced Log Viewer**
- **Complete Log Viewer Implementation**:
  ```python
  # SRC/cuepoint/ui/widgets/log_viewer.py
  from PySide6.QtWidgets import (
      QDialog, QVBoxLayout, QHBoxLayout, QLabel, QPushButton,
      QTextEdit, QComboBox, QCheckBox
  )
  from PySide6.QtCore import Qt, QTimer
  from PySide6.QtGui import QFont, QTextCharFormat, QColor
  from pathlib import Path
  from cuepoint.utils.paths import AppPaths
  import platform
  import subprocess
  
  class LogViewer(QDialog):
      """Enhanced log viewer with filtering and search"""
      
      def __init__(self, parent=None):
          super().__init__(parent)
          self.setWindowTitle("Log Viewer")
          self.setMinimumSize(800, 600)
          self.auto_refresh = False
          self.init_ui()
      
      def init_ui(self):
          """Initialize UI"""
          layout = QVBoxLayout()
          
          # Controls
          controls_layout = QHBoxLayout()
          
          # Log level filter
          level_label = QLabel("Filter by level:")
          controls_layout.addWidget(level_label)
          
          self.level_combo = QComboBox()
          self.level_combo.addItems(["All", "DEBUG", "INFO", "WARNING", "ERROR", "CRITICAL"])
          self.level_combo.currentTextChanged.connect(self.load_logs)
          controls_layout.addWidget(self.level_combo)
          
          # Search
          search_label = QLabel("Search:")
          controls_layout.addWidget(search_label)
          
          self.search_input = QLineEdit()
          self.search_input.setPlaceholderText("Search logs...")
          self.search_input.textChanged.connect(self.filter_logs)
          controls_layout.addWidget(self.search_input)
          
          # Auto-refresh
          self.auto_refresh_checkbox = QCheckBox("Auto-refresh")
          self.auto_refresh_checkbox.toggled.connect(self.toggle_auto_refresh)
          controls_layout.addWidget(self.auto_refresh_checkbox)
          
          controls_layout.addStretch()
          
          layout.addLayout(controls_layout)
          
          # Log text area
          self.log_text = QTextEdit()
          self.log_text.setReadOnly(True)
          self.log_text.setFont(QFont("Courier", 10))
          self.log_text.setLineWrapMode(QTextEdit.NoWrap)
          layout.addWidget(self.log_text)
          
          # Buttons
          button_layout = QHBoxLayout()
          
          refresh_btn = QPushButton("Refresh")
          refresh_btn.clicked.connect(self.load_logs)
          button_layout.addWidget(refresh_btn)
          
          clear_btn = QPushButton("Clear Logs")
          clear_btn.clicked.connect(self.clear_logs)
          button_layout.addWidget(clear_btn)
          
          export_btn = QPushButton("Export...")
          export_btn.clicked.connect(self.export_logs)
          button_layout.addWidget(export_btn)
          
          open_folder_btn = QPushButton("Open Logs Folder")
          open_folder_btn.clicked.connect(self.open_logs_folder)
          button_layout.addWidget(open_folder_btn)
          
          button_layout.addStretch()
          
          close_btn = QPushButton("Close")
          close_btn.clicked.connect(self.accept)
          button_layout.addWidget(close_btn)
          
          layout.addLayout(button_layout)
          
          self.setLayout(layout)
          
          # Load logs
          self.load_logs()
      
      def load_logs(self):
          """Load and display log files"""
          log_dir = AppPaths.logs_dir()
          log_file = log_dir / "cuepoint.log"
          
          if not log_file.exists():
              self.log_text.setPlainText("No log file found.")
              return
          
          # Read log file
          try:
              content = log_file.read_text(encoding='utf-8')
              
              # Filter by level
              level = self.level_combo.currentText()
              if level != "All":
                  lines = content.splitlines()
                  filtered_lines = [
                      line for line in lines
                      if f"[{level}]" in line
                  ]
                  content = "\n".join(filtered_lines)
              
              # Apply search filter
              self.filtered_content = content
              self.filter_logs()
              
          except Exception as e:
              self.log_text.setPlainText(f"Error reading log file: {e}")
      
      def filter_logs(self):
          """Filter logs by search term"""
          search_term = self.search_input.text().lower()
          
          if not search_term:
              self.log_text.setPlainText(self.filtered_content)
              return
          
          lines = self.filtered_content.splitlines()
          filtered = [line for line in lines if search_term in line.lower()]
          self.log_text.setPlainText("\n".join(filtered))
          
          # Highlight search term
          # (implementation for syntax highlighting)
      
      def toggle_auto_refresh(self, enabled: bool):
          """Toggle auto-refresh"""
          self.auto_refresh = enabled
          if enabled:
              self.refresh_timer = QTimer()
              self.refresh_timer.timeout.connect(self.load_logs)
              self.refresh_timer.start(2000)  # Refresh every 2 seconds
          else:
              if hasattr(self, 'refresh_timer'):
                  self.refresh_timer.stop()
      
      def clear_logs(self):
          """Clear log files (with confirmation)"""
          from PySide6.QtWidgets import QMessageBox
          
          reply = QMessageBox.question(
              self,
              "Clear Logs",
              "Are you sure you want to clear all log files?",
              QMessageBox.Yes | QMessageBox.No,
              QMessageBox.No
          )
          
          if reply == QMessageBox.Yes:
              log_dir = AppPaths.logs_dir()
              for log_file in log_dir.glob("*.log*"):
                  try:
                      log_file.unlink()
                  except Exception as e:
                      logging.error(f"Error deleting log file {log_file}: {e}")
              
              self.load_logs()
      
      def export_logs(self):
          """Export logs to file"""
          from PySide6.QtWidgets import QFileDialog
          from cuepoint.utils.paths import AppPaths
          
          file_path, _ = QFileDialog.getSaveFileName(
              self,
              "Export Logs",
              str(AppPaths.exports_dir() / "cuepoint-logs.txt"),
              "Text Files (*.txt);;All Files (*)"
          )
          
          if file_path:
              try:
                  Path(file_path).write_text(self.log_text.toPlainText(), encoding='utf-8')
                  QMessageBox.information(self, "Export Complete", f"Logs exported to:\n{file_path}")
              except Exception as e:
                  QMessageBox.critical(self, "Export Failed", f"Failed to export logs:\n{e}")
      
      def open_logs_folder(self):
          """Open logs folder in file explorer"""
          log_dir = AppPaths.logs_dir()
          
          if platform.system() == "Windows":
              subprocess.Popen(f'explorer "{log_dir}"')
          elif platform.system() == "Darwin":
              subprocess.Popen(["open", str(log_dir)])
          else:
              subprocess.Popen(["xdg-open", str(log_dir)])
  ```

### Network Behavior - Complete Implementation

**1.9.3.3 Complete Network Client**
- **Enhanced Network Client with All Features**:
  ```python
  # SRC/cuepoint/core/network_client.py
  """Network client with timeouts, retries, and rate limiting"""
  import requests
  from requests.adapters import HTTPAdapter
  from urllib3.util.retry import Retry
  from typing import Optional, Dict, Any
  import time
  import logging
  
  logger = logging.getLogger(__name__)
  
  class NetworkClient:
      """Network client with reliability features"""
      
      def __init__(self, timeout: tuple = (5, 30), max_retries: int = 3):
          self.session = requests.Session()
          self.timeout = timeout
          self.max_retries = max_retries
          self.rate_limit_delay = 0.5  # 500ms between requests
          self.last_request_time = 0
          
          # Retry strategy
          retry_strategy = Retry(
              total=max_retries,
              backoff_factor=0.5,
              status_forcelist=[429, 500, 502, 503, 504],
              allowed_methods=["GET", "POST"],
              raise_on_status=False
          )
          
          adapter = HTTPAdapter(max_retries=retry_strategy)
          self.session.mount("http://", adapter)
          self.session.mount("https://", adapter)
          
          # Set default headers
          self.session.headers.update({
              'User-Agent': 'CuePoint/1.0',
              'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',
              'Accept-Language': 'en-US,en;q=0.5',
          })
      
      def get(self, url: str, **kwargs) -> requests.Response:
          """GET request with rate limiting and timeout"""
          # Rate limiting
          elapsed = time.time() - self.last_request_time
          if elapsed < self.rate_limit_delay:
              time.sleep(self.rate_limit_delay - elapsed)
          
          self.last_request_time = time.time()
          
          # Make request
          try:
              response = self.session.get(
                  url,
                  timeout=self.timeout,
                  **kwargs
              )
              response.raise_for_status()
              return response
          except requests.exceptions.Timeout:
              logger.warning(f"Request timeout: {url}")
              raise NetworkTimeoutError(f"Request timed out: {url}")
          except requests.exceptions.ConnectionError:
              logger.warning(f"Connection error: {url}")
              raise NetworkConnectionError(f"Connection failed: {url}")
          except requests.exceptions.HTTPError as e:
              logger.error(f"HTTP error {e.response.status_code}: {url}")
              raise
          except requests.exceptions.RequestException as e:
              logger.error(f"Request error: {url} - {e}")
              raise
      
      def check_connectivity(self) -> bool:
          """Check if network is available"""
          try:
              response = self.session.get(
                  "https://www.google.com",
                  timeout=(2, 5)
              )
              return response.status_code == 200
          except Exception:
              return False
  ```

**1.9.3.4 Complete Offline Handling**
- **Enhanced Offline Handling**:
  ```python
  # In SRC/cuepoint/core/scraper.py
  def scrape_with_offline_handling(self, url: str, use_cache: bool = True):
      """Scrape with comprehensive offline handling"""
      # Check network availability
      if not self.network_client.check_connectivity():
          logger.warning("Network unavailable, using cache only")
          if use_cache:
              cached = self.cache.get(url)
              if cached:
                  logger.info(f"Using cached data for {url}")
                  return cached
              else:
                  raise NetworkUnavailableError(
                      "Network unavailable and no cached data available. "
                      "Please check your internet connection."
                  )
          else:
              raise NetworkUnavailableError("Network unavailable")
      
      # Try network request with fallback to cache
      try:
          response = self.network_client.get(url)
          # Cache successful response
          self.cache.set(url, response)
          return response
      except (NetworkTimeoutError, NetworkConnectionError) as e:
          logger.warning(f"Network error: {e}, trying cache...")
          if use_cache:
              cached = self.cache.get(url)
              if cached:
                  logger.info(f"Using cached data for {url} due to network error")
                  return cached
          raise
  ```

### Data Retention - Complete Implementation

**1.9.4.3 Enhanced Cache Manager**
- **Complete Cache Management**:
  ```python
  # SRC/cuepoint/utils/cache_manager.py
  """Comprehensive cache management with size and age limits"""
  from pathlib import Path
  from datetime import datetime, timedelta
  from cuepoint.utils.paths import AppPaths
  import shutil
  import logging
  
  logger = logging.getLogger(__name__)
  
  class CacheManager:
      """Manage application cache with size and age limits"""
      
      DEFAULT_MAX_SIZE_MB = 500
      DEFAULT_MAX_AGE_DAYS = 7
      
      @staticmethod
      def get_cache_size() -> int:
          """Get total cache size in bytes"""
          cache_dir = AppPaths.cache_dir()
          total = 0
          for file in cache_dir.rglob("*"):
              if file.is_file():
                  total += file.stat().st_size
          return total
      
      @staticmethod
      def get_cache_size_mb() -> float:
          """Get total cache size in MB"""
          return CacheManager.get_cache_size() / (1024 * 1024)
      
      @staticmethod
      def get_cache_file_count() -> int:
          """Get number of cache files"""
          cache_dir = AppPaths.cache_dir()
          return len(list(cache_dir.rglob("*")))
      
      @staticmethod
      def clear_cache():
          """Clear all cache files"""
          cache_dir = AppPaths.cache_dir()
          cleared_count = 0
          cleared_size = 0
          
          for item in cache_dir.iterdir():
              try:
                  if item.is_file():
                      size = item.stat().st_size
                      item.unlink()
                      cleared_count += 1
                      cleared_size += size
                  elif item.is_dir():
                      shutil.rmtree(item)
                      cleared_count += 1
              except Exception as e:
                  logger.error(f"Error clearing cache item {item}: {e}")
          
          logger.info(f"Cleared {cleared_count} cache items ({cleared_size / (1024*1024):.1f} MB)")
          return cleared_count, cleared_size
      
      @staticmethod
      def prune_cache(
          max_size_mb: int = DEFAULT_MAX_SIZE_MB,
          max_age_days: int = DEFAULT_MAX_AGE_DAYS
      ):
          """Prune cache to size and age limits"""
          cache_dir = AppPaths.cache_dir()
          max_size_bytes = max_size_mb * 1024 * 1024
          max_age = timedelta(days=max_age_days)
          
          # Get all cache files with metadata
          files = []
          for file in cache_dir.rglob("*"):
              if file.is_file():
                  stat = file.stat()
                  age = datetime.now() - datetime.fromtimestamp(stat.st_mtime)
                  files.append({
                      "path": file,
                      "size": stat.st_size,
                      "age": age,
                      "mtime": stat.st_mtime
                  })
          
          # Sort by age (oldest first)
          files.sort(key=lambda x: x["mtime"])
          
          # Calculate current size
          current_size = sum(f["size"] for f in files)
          
          # Remove old files first
          removed_count = 0
          removed_size = 0
          
          for file_info in files:
              if current_size <= max_size_bytes and file_info["age"] <= max_age:
                  break
              
              # Remove file
              try:
                  file_info["path"].unlink()
                  current_size -= file_info["size"]
                  removed_count += 1
                  removed_size += file_info["size"]
              except Exception as e:
                  logger.error(f"Error removing cache file {file_info['path']}: {e}")
          
          if removed_count > 0:
              logger.info(
                  f"Pruned cache: removed {removed_count} files "
                  f"({removed_size / (1024*1024):.1f} MB)"
              )
          
          return removed_count, removed_size
      
      @staticmethod
      def get_cache_info() -> dict:
          """Get cache information for diagnostics"""
          return {
              "size_bytes": CacheManager.get_cache_size(),
              "size_mb": CacheManager.get_cache_size_mb(),
              "file_count": CacheManager.get_cache_file_count(),
              "directory": str(AppPaths.cache_dir())
          }
  ```

**1.9.4.4 Enhanced History Manager**
- **Complete History Management**:
  ```python
  # SRC/cuepoint/utils/history_manager.py
  """History file management with retention policies"""
  from pathlib import Path
  from datetime import datetime, timedelta
  from cuepoint.utils.paths import AppPaths
  from typing import List, Optional
  import logging
  
  logger = logging.getLogger(__name__)
  
  class HistoryManager:
      """Manage past search history files"""
      
      DEFAULT_MAX_FILES = 50
      DEFAULT_MAX_AGE_DAYS = 90
      
      @staticmethod
      def get_recent_files(
          max_files: int = DEFAULT_MAX_FILES,
          max_days: int = DEFAULT_MAX_AGE_DAYS
      ) -> List[Path]:
          """Get recent CSV export files"""
          exports_dir = AppPaths.exports_dir()
          cutoff_date = datetime.now() - timedelta(days=max_days)
          
          files = []
          for file in exports_dir.glob("*.csv"):
              try:
                  mtime = datetime.fromtimestamp(file.stat().st_mtime)
                  if mtime > cutoff_date:
                      files.append({
                          "path": file,
                          "mtime": mtime,
                          "size": file.stat().st_size
                      })
              except Exception as e:
                  logger.warning(f"Error reading file {file}: {e}")
          
          # Sort by modification time (newest first)
          files.sort(key=lambda x: x["mtime"], reverse=True)
          
          # Return up to max_files
          return [f["path"] for f in files[:max_files]]
      
      @staticmethod
      def get_history_info() -> dict:
          """Get history information"""
          recent_files = HistoryManager.get_recent_files()
          total_size = sum(f.stat().st_size for f in recent_files)
          
          return {
              "file_count": len(recent_files),
              "total_size_bytes": total_size,
              "total_size_mb": total_size / (1024 * 1024),
              "directory": str(AppPaths.exports_dir())
          }
      
      @staticmethod
      def cleanup_old_files(max_days: int = DEFAULT_MAX_AGE_DAYS, dry_run: bool = False) -> int:
          """Clean up old history files (user-controlled)"""
          exports_dir = AppPaths.exports_dir()
          cutoff_date = datetime.now() - timedelta(days=max_days)
          
          removed_count = 0
          for file in exports_dir.glob("*.csv"):
              try:
                  mtime = datetime.fromtimestamp(file.stat().st_mtime)
                  if mtime < cutoff_date:
                      if not dry_run:
                          file.unlink()
                      removed_count += 1
              except Exception as e:
                  logger.error(f"Error cleaning up file {file}: {e}")
          
          if removed_count > 0:
              logger.info(f"Cleaned up {removed_count} old history files")
          
          return removed_count
  ```

### Diagnostics - Complete Implementation

**1.9.5.4 Complete Diagnostic Collection**
- **Enhanced Diagnostic Collector**:
  ```python
  # SRC/cuepoint/utils/diagnostics.py
  """Comprehensive diagnostic information collection"""
  import platform
  import psutil
  import json
  import sys
  from pathlib import Path
  from datetime import datetime
  from typing import Dict, Any, List
  from cuepoint.utils.paths import AppPaths
  from cuepoint.utils.platform import get_platform_info
  from cuepoint.version import get_build_info
  from cuepoint.utils.cache_manager import CacheManager
  from cuepoint.utils.history_manager import HistoryManager
  from PySide6.QtCore import QSettings
  
  class DiagnosticCollector:
      """Collect comprehensive diagnostic information"""
      
      @staticmethod
      def collect_all() -> Dict[str, Any]:
          """Collect all diagnostic information"""
          return {
              "timestamp": datetime.now().isoformat(),
              "application": DiagnosticCollector.collect_app_info(),
              "system": DiagnosticCollector.collect_system_info(),
              "configuration": DiagnosticCollector.collect_config_info(),
              "storage": DiagnosticCollector.collect_storage_info(),
              "logs": DiagnosticCollector.collect_log_info(),
              "errors": DiagnosticCollector.collect_error_info(),
              "cache": DiagnosticCollector.collect_cache_info(),
              "history": DiagnosticCollector.collect_history_info()
          }
      
      @staticmethod
      def collect_app_info() -> Dict[str, Any]:
          """Collect application information"""
          build_info = get_build_info()
          return {
              "version": build_info["version"],
              "version_string": build_info.get("version_string"),
              "build_number": build_info.get("build_number"),
              "commit_sha": build_info.get("commit_sha"),
              "short_commit_sha": build_info.get("short_commit_sha"),
              "build_date": build_info.get("build_date"),
              "install_path": str(AppPaths.app_dir()),
              "python_version": sys.version,
              "python_executable": sys.executable,
              "is_frozen": getattr(sys, 'frozen', False)
          }
      
      @staticmethod
      def collect_system_info() -> Dict[str, Any]:
          """Collect system information"""
          platform_info = get_platform_info()
          return {
              "platform": platform_info.platform,
              "architecture": platform_info.architecture,
              "os_version": platform_info.os_version,
              "is_64bit": platform_info.is_64bit,
              "is_apple_silicon": platform_info.is_apple_silicon,
              "cpu_count": psutil.cpu_count(),
              "memory": {
                  "total_gb": psutil.virtual_memory().total / (1024**3),
                  "available_gb": psutil.virtual_memory().available / (1024**3),
                  "percent": psutil.virtual_memory().percent
              },
              "disk": {
                  "total_gb": psutil.disk_usage('/').total / (1024**3),
                  "free_gb": psutil.disk_usage('/').free / (1024**3),
                  "percent": psutil.disk_usage('/').percent
              }
          }
      
      @staticmethod
      def collect_config_info() -> Dict[str, Any]:
          """Collect configuration information (non-sensitive)"""
          settings = QSettings()
          config_file = AppPaths.config_file()
          
          config = {}
          
          # Read settings
          config["settings"] = {
              "output_directory": settings.value("output_directory", ""),
              "cache_enabled": settings.value("cache_enabled", True),
              "cache_size_mb": settings.value("cache_size_mb", 500),
              "auto_update_check": settings.value("auto_update_check", True),
          }
          
          # Read config file if exists
          if config_file.exists():
              try:
                  import yaml
                  with open(config_file, 'r') as f:
                      file_config = yaml.safe_load(f)
                      # Remove sensitive information
                      if isinstance(file_config, dict):
                          file_config.pop("api_keys", None)
                          file_config.pop("secrets", None)
                      config["file"] = file_config
              except Exception as e:
                  config["file_error"] = str(e)
          
          return config
      
      @staticmethod
      def collect_storage_info() -> Dict[str, Any]:
          """Collect storage location information"""
          paths = AppPaths.get_all_paths()
          
          # Check path accessibility
          path_status = {}
          for name, path_str in paths.items():
              path = Path(path_str)
              path_status[name] = {
                  "path": path_str,
                  "exists": path.exists(),
                  "writable": os.access(path if path.exists() else path.parent, os.W_OK),
                  "size_mb": sum(f.stat().st_size for f in path.rglob("*") if f.is_file()) / (1024*1024) if path.exists() else 0
              }
          
          return {
              "paths": paths,
              "status": path_status
          }
      
      @staticmethod
      def collect_log_info() -> Dict[str, Any]:
          """Collect log file information"""
          logs_dir = AppPaths.logs_dir()
          log_files = list(logs_dir.glob("*.log*"))
          
          return {
              "log_directory": str(logs_dir),
              "log_files": [f.name for f in log_files],
              "latest_log": log_files[-1].name if log_files else None,
              "log_count": len(log_files),
              "total_size_mb": sum(f.stat().st_size for f in log_files) / (1024*1024),
              "recent_logs": DiagnosticCollector._get_recent_log_lines(200)
          }
      
      @staticmethod
      def _get_recent_log_lines(count: int = 200) -> List[str]:
          """Get recent log lines"""
          log_file = AppPaths.logs_dir() / "cuepoint.log"
          if not log_file.exists():
              return []
          
          try:
              lines = log_file.read_text(encoding='utf-8').splitlines()
              return lines[-count:] if len(lines) > count else lines
          except Exception as e:
              return [f"Error reading logs: {e}"]
      
      @staticmethod
      def collect_error_info() -> List[Dict[str, Any]]:
          """Collect recent error information"""
          errors = []
          
          # Read crash logs
          crash_logs = list(AppPaths.logs_dir().glob("crash-*.log"))
          for crash_log in sorted(crash_logs, key=lambda p: p.stat().st_mtime, reverse=True)[:5]:
              try:
                  errors.append({
                      "type": "crash",
                      "file": crash_log.name,
                      "timestamp": datetime.fromtimestamp(crash_log.stat().st_mtime).isoformat(),
                      "preview": crash_log.read_text(encoding='utf-8')[:500]
                  })
              except Exception:
                  pass
          
          return errors
      
      @staticmethod
      def collect_cache_info() -> Dict[str, Any]:
          """Collect cache information"""
          return CacheManager.get_cache_info()
      
      @staticmethod
      def collect_history_info() -> Dict[str, Any]:
          """Collect history information"""
          return HistoryManager.get_history_info()
  ```

**1.9.5.5 Complete Support Bundle Generator**
- **Enhanced Support Bundle**:
  ```python
  # SRC/cuepoint/utils/support_bundle.py
  """Generate comprehensive support bundle for diagnostics"""
  import zipfile
  import json
  from pathlib import Path
  from datetime import datetime
  from cuepoint.utils.paths import AppPaths
  from cuepoint.utils.diagnostics import DiagnosticCollector
  import logging
  
  logger = logging.getLogger(__name__)
  
  class SupportBundleGenerator:
      """Generate support bundle ZIP file"""
      
      @staticmethod
      def generate_bundle(output_path: Path) -> Path:
          """Generate support bundle"""
          timestamp = datetime.now().strftime('%Y%m%d-%H%M%S')
          bundle_path = output_path / f"cuepoint-support-{timestamp}.zip"
          
          logger.info(f"Generating support bundle: {bundle_path}")
          
          try:
              with zipfile.ZipFile(bundle_path, 'w', zipfile.ZIP_DEFLATED) as zipf:
                  # Diagnostics JSON
                  diagnostics = DiagnosticCollector.collect_all()
                  zipf.writestr(
                      "diagnostics.json",
                      json.dumps(diagnostics, indent=2, default=str)
                  )
                  
                  # Log files
                  log_dir = AppPaths.logs_dir()
                  for log_file in log_dir.glob("*.log*"):
                      try:
                          zipf.write(log_file, f"logs/{log_file.name}")
                      except Exception as e:
                          logger.warning(f"Could not include log file {log_file}: {e}")
                  
                  # Crash logs
                  for crash_file in log_dir.glob("crash-*.log"):
                      try:
                          zipf.write(crash_file, f"crashes/{crash_file.name}")
                      except Exception as e:
                          logger.warning(f"Could not include crash log {crash_file}: {e}")
                  
                  # Config file (if exists, sanitized)
                  config_file = AppPaths.config_file()
                  if config_file.exists():
                      try:
                          import yaml
                          with open(config_file, 'r') as f:
                              config = yaml.safe_load(f)
                              # Remove sensitive data
                              if isinstance(config, dict):
                                  config.pop("api_keys", None)
                                  config.pop("secrets", None)
                          zipf.writestr(
                              "config.yaml",
                              yaml.dump(config, default_flow_style=False)
                          )
                      except Exception as e:
                          logger.warning(f"Could not include config: {e}")
                  
                  # README
                  readme = f"""
  CuePoint Support Bundle
  Generated: {datetime.now().isoformat()}
  
  This bundle contains diagnostic information to help diagnose issues.
  
  Contents:
  - diagnostics.json: System and application information
  - logs/: Application log files
  - crashes/: Crash log files (if any)
  - config.yaml: Configuration (sanitized, no secrets)
  
  Please attach this file when reporting issues.
                  """
                  zipf.writestr("README.txt", readme)
              
              logger.info(f"Support bundle created: {bundle_path}")
              return bundle_path
              
          except Exception as e:
              logger.error(f"Failed to generate support bundle: {e}")
              raise
  ```

## Testing and Validation

### Operational Testing Scenarios
- **Test 1**: Path initialization on clean system
- **Test 2**: Log rotation at size limit
- **Test 3**: Network retry on failure
- **Test 4**: Cache pruning at size limit
- **Test 5**: Support bundle generation

## Performance Benchmarks

### Operational Performance
- **Path Initialization**: < 100ms
- **Log Write**: < 10ms per entry
- **Cache Pruning**: < 1 second for 1000 files
- **Support Bundle**: < 5 seconds

## Edge Cases

### Storage Edge Cases
- **Case 1**: Path creation fails (permissions)
  - **Handling**: Show error, suggest solutions
- **Case 2**: Disk full
  - **Handling**: Check before operations, show error
- **Case 3**: Path too long (Windows)
  - **Handling**: Use long path support, validate

### Logging Edge Cases
- **Case 1**: Log directory not writable
  - **Handling**: Fall back to temp directory, log warning
- **Case 2**: Log file locked
  - **Handling**: Use separate file, retry
- **Case 3**: Disk full during logging
  - **Handling**: Prune old logs, continue

## References

- Main document: `../01_Product_Requirements_and_Definition.md`
- Related: Step 6 (Runtime Design), Step 9.5 (Support UX)
- QStandardPaths: Qt documentation
- Logging: Python logging documentation
- Network: requests library documentation

