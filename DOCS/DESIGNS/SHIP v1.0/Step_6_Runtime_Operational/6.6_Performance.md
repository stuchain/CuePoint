# Implementation Step 6.6: Performance

## Implementation Overview
**What We're Building**: A comprehensive performance optimization system that ensures UI responsiveness through background workers, implements progress throttling to prevent UI blocking, establishes performance budgets with monitoring, optimizes large result set handling, and provides performance diagnostics. This system ensures that CuePoint remains responsive during long-running operations, provides smooth user experience even with large datasets, and enables performance monitoring and optimization while maintaining code maintainability.

## Implementation Tasks

### Task 6.6.1: Implement UI Responsiveness Measures

**What to Build**
- Background worker system
- UI thread protection
- Progress update throttling
- Non-blocking operation patterns
- Responsiveness monitoring

**Implementation Details**

**6.6.1.1 Background Worker System**
- **Purpose**: Move long-running operations off UI thread
- **Rationale**:
  - Prevents UI freezing
  - Maintains user interaction
  - Provides better user experience
  - Enables cancellation
- **File to Create/Modify**: `SRC/cuepoint/utils/workers.py` (may need to create)
- **Implementation**:
  ```python
  from PySide6.QtCore import QThread, Signal, QObject
  from typing import Callable, Any, Optional
  
  class Worker(QThread):
      """Background worker thread for long-running operations."""
      
      # Signals
      started = Signal()
      progress = Signal(int, int)  # current, total
      status = Signal(str)  # status message
      finished = Signal(object)  # result
      error = Signal(Exception)  # error
      
      def __init__(self, task: Callable, *args, **kwargs):
          """Initialize worker.
          
          Args:
              task: Function to run in background
              *args, **kwargs: Arguments to pass to task
          """
          super().__init__()
          self.task = task
          self.args = args
          self.kwargs = kwargs
          self._cancelled = False
      
      def run(self):
          """Run task in background thread."""
          try:
              self.started.emit()
              result = self.task(*self.args, **self.kwargs)
              if not self._cancelled:
                  self.finished.emit(result)
          except Exception as e:
              if not self._cancelled:
                  self.error.emit(e)
      
      def cancel(self):
          """Cancel worker execution."""
          self._cancelled = True
          self.terminate()
  
  class WorkerManager(QObject):
      """Manage background workers."""
      
      def __init__(self):
          super().__init__()
          self.workers = []
      
      def start_worker(self, task: Callable, *args, **kwargs) -> Worker:
          """Start a background worker.
          
          Args:
              task: Function to run
              *args, **kwargs: Arguments
              
          Returns:
              Worker instance
          """
          worker = Worker(task, *args, **kwargs)
          self.workers.append(worker)
          worker.finished.connect(lambda: self.workers.remove(worker))
          worker.error.connect(lambda: self.workers.remove(worker))
          worker.start()
          return worker
      
      def cancel_all(self):
          """Cancel all running workers."""
          for worker in self.workers[:]:
              worker.cancel()
              self.workers.remove(worker)
  ```
- **Usage**: Use for all long-running operations
- **Benefits**: Keeps UI responsive

**6.6.1.2 UI Thread Protection**
- **Purpose**: Ensure UI updates happen on UI thread
- **Implementation**:
  ```python
  from PySide6.QtCore import QTimer, QMetaObject, Qt
  
  class UIThreadHelper:
      """Helper for UI thread operations."""
      
      @staticmethod
      def call_on_ui_thread(func: Callable, *args, **kwargs):
          """Call function on UI thread.
          
          Args:
              func: Function to call
              *args, **kwargs: Arguments
          """
          app = QApplication.instance()
          if app is None:
              return
          
          # Use QMetaObject.invokeMethod for thread-safe call
          QMetaObject.invokeMethod(
              app,
              lambda: func(*args, **kwargs),
              Qt.QueuedConnection
          )
      
      @staticmethod
      def is_ui_thread() -> bool:
          """Check if current thread is UI thread.
          
          Returns:
              True if on UI thread
          """
          app = QApplication.instance()
          if app is None:
              return False
          return QThread.currentThread() == app.thread()
  ```
- **Usage**: Use when updating UI from background thread
- **Safety**: Prevents UI crashes from cross-thread access

**6.6.1.3 Progress Update Throttling**
- **Purpose**: Limit progress update frequency to prevent UI blocking
- **Rationale**:
  - Too many updates can block UI
  - Users don't need millisecond updates
  - Reduces overhead
  - Improves performance
- **Implementation**:
  ```python
  import time
  from typing import Optional
  
  class ProgressThrottler:
      """Throttle progress updates to prevent UI blocking."""
      
      def __init__(self, min_interval: float = 0.25):
          """Initialize throttler.
          
          Args:
              min_interval: Minimum time between updates (seconds)
          """
          self.min_interval = min_interval
          self.last_update = 0.0
      
      def should_update(self) -> bool:
          """Check if update should be sent.
          
          Returns:
              True if enough time has passed
          """
          now = time.time()
          if now - self.last_update >= self.min_interval:
              self.last_update = now
              return True
          return False
      
      def force_update(self):
          """Force next update to be sent."""
          self.last_update = 0.0
  ```
- **Usage**: Check before emitting progress signals
- **Benefits**: Reduces UI update overhead

### Task 6.6.2: Implement Performance Budgets

**What to Build**
- Performance budget definitions
- Performance monitoring
- Budget violation detection
- Performance reporting
- Optimization guidance

**Implementation Details**

**6.6.2.1 Performance Budget Definitions**
- **Purpose**: Define performance targets
- **Performance Budgets**:
  - Startup to ready: < 2 seconds
  - Table filter apply: < 200ms (for 1k rows, debounced)
  - Per-track processing: Progress update at least every 250ms
  - UI response: < 100ms for user actions
  - Memory usage: < 500MB for typical operation
- **Implementation**:
  ```python
  from dataclasses import dataclass
  from typing import Optional
  
  @dataclass
  class PerformanceBudget:
      """Performance budget definition."""
      name: str
      target_ms: float
      warning_ms: Optional[float] = None
      critical_ms: Optional[float] = None
      
      def check(self, actual_ms: float) -> tuple[bool, str]:
          """Check if budget is met.
          
          Args:
              actual_ms: Actual time in milliseconds
              
          Returns:
              Tuple of (is_ok, status_message)
          """
          if self.critical_ms and actual_ms > self.critical_ms:
              return False, f"CRITICAL: {actual_ms:.1f}ms > {self.critical_ms:.1f}ms"
          elif self.warning_ms and actual_ms > self.warning_ms:
              return True, f"WARNING: {actual_ms:.1f}ms > {self.warning_ms:.1f}ms"
          elif actual_ms > self.target_ms:
              return True, f"SLOW: {actual_ms:.1f}ms > {self.target_ms:.1f}ms"
          else:
              return True, f"OK: {actual_ms:.1f}ms"
  
  class PerformanceBudgets:
      """Performance budget definitions."""
      
      STARTUP = PerformanceBudget("startup", 2000, warning_ms=3000, critical_ms=5000)
      TABLE_FILTER = PerformanceBudget("table_filter", 200, warning_ms=500, critical_ms=1000)
      TRACK_PROCESSING = PerformanceBudget("track_processing", 250, warning_ms=500, critical_ms=1000)
      UI_RESPONSE = PerformanceBudget("ui_response", 100, warning_ms=200, critical_ms=500)
      MEMORY_USAGE = PerformanceBudget("memory_usage", 500 * 1024 * 1024, warning_ms=750 * 1024 * 1024, critical_ms=1000 * 1024 * 1024)  # MB
  ```
- **Usage**: Check budgets during operations
- **Benefits**: Identifies performance issues early

**6.6.2.2 Performance Monitoring**
- **Purpose**: Monitor performance metrics
- **Implementation**:
  ```python
  import time
  import psutil
  import os
  from contextlib import contextmanager
  from typing import Dict, List
  
  class PerformanceMonitor:
      """Monitor performance metrics."""
      
      _metrics: List[Dict[str, Any]] = []
      
      @staticmethod
      @contextmanager
      def measure(operation_name: str, budget: Optional[PerformanceBudget] = None):
          """Context manager to measure operation performance.
          
          Usage:
              with PerformanceMonitor.measure("process_file"):
                  # operation code
          
          Args:
              operation_name: Name of operation
              budget: Performance budget to check
          """
          start_time = time.time()
          start_memory = PerformanceMonitor._get_memory_usage()
          
          try:
              yield
              duration_ms = (time.time() - start_time) * 1000
              end_memory = PerformanceMonitor._get_memory_usage()
              memory_delta = end_memory - start_memory
              
              metric = {
                  "operation": operation_name,
                  "duration_ms": duration_ms,
                  "memory_delta_mb": memory_delta / (1024 * 1024),
                  "timestamp": time.time(),
              }
              
              if budget:
                  is_ok, status = budget.check(duration_ms)
                  metric["budget_status"] = status
                  metric["budget_ok"] = is_ok
                  
                  if not is_ok or "WARNING" in status:
                      logger = logging.getLogger(__name__)
                      logger.warning(f"Performance: {operation_name} - {status}")
              
              PerformanceMonitor._metrics.append(metric)
              
          except Exception as e:
              duration_ms = (time.time() - start_time) * 1000
              logger = logging.getLogger(__name__)
              logger.error(f"Performance measurement failed for {operation_name}: {e}")
              raise
      
      @staticmethod
      def _get_memory_usage() -> int:
          """Get current memory usage in bytes.
          
          Returns:
              Memory usage in bytes
          """
          process = psutil.Process(os.getpid())
          return process.memory_info().rss
      
      @staticmethod
      def get_metrics() -> List[Dict[str, Any]]:
          """Get collected performance metrics.
          
          Returns:
              List of metric dictionaries
          """
          return PerformanceMonitor._metrics.copy()
      
      @staticmethod
      def clear_metrics():
          """Clear collected metrics."""
          PerformanceMonitor._metrics.clear()
      
      @staticmethod
      def get_summary() -> Dict[str, Any]:
          """Get performance summary.
          
          Returns:
              Dictionary with performance summary
          """
          if not PerformanceMonitor._metrics:
              return {}
          
          # Group by operation
          by_operation = {}
          for metric in PerformanceMonitor._metrics:
              op = metric["operation"]
              if op not in by_operation:
                  by_operation[op] = []
              by_operation[op].append(metric)
          
          summary = {}
          for op, metrics in by_operation.items():
              durations = [m["duration_ms"] for m in metrics]
              summary[op] = {
                  "count": len(metrics),
                  "avg_ms": sum(durations) / len(durations),
                  "min_ms": min(durations),
                  "max_ms": max(durations),
                  "total_ms": sum(durations),
              }
          
          return summary
  ```
- **Usage**: Wrap operations to measure performance
- **Benefits**: Identifies performance bottlenecks

### Task 6.6.3: Optimize Large Result Set Handling

**What to Build**
- Efficient table population
- Virtual scrolling (if needed)
- Batch updates
- Lazy loading
- Memory-efficient data structures

**Implementation Details**

**6.6.3.1 Efficient Table Population**
- **Purpose**: Populate large tables efficiently
- **Problem**: O(n²) complexity in naive implementations
- **Solution**: Batch updates, use QAbstractItemModel efficiently
- **Implementation**:
  ```python
  from PySide6.QtCore import QAbstractTableModel, Qt, QModelIndex
  
  class EfficientTableModel(QAbstractTableModel):
      """Efficient table model for large datasets."""
      
      def __init__(self, data: List[List[Any]]):
          """Initialize model.
          
          Args:
              data: List of rows, each row is list of values
          """
          super().__init__()
          self._data = data
          self._headers = []
      
      def rowCount(self, parent=QModelIndex()) -> int:
          return len(self._data)
      
      def columnCount(self, parent=QModelIndex()) -> int:
          if self._data:
              return len(self._data[0])
          return 0
      
      def data(self, index: QModelIndex, role=Qt.DisplayRole):
          if not index.isValid():
              return None
          
          if role == Qt.DisplayRole:
              row = index.row()
              col = index.column()
              if 0 <= row < len(self._data) and 0 <= col < len(self._data[row]):
                  return self._data[row][col]
          
          return None
      
      def setDataBatch(self, data: List[List[Any]]):
          """Set data in batch (efficient).
          
          Args:
              data: New data
          """
          self.beginResetModel()
          self._data = data
          self.endResetModel()
  ```
- **Benefits**: Efficient for large datasets
- **Usage**: Use for results table

**6.6.3.2 Debounced Filtering**
- **Purpose**: Prevent excessive filtering operations
- **Implementation**:
  ```python
  from PySide6.QtCore import QTimer
  
  class DebouncedFilter:
      """Debounced filter to prevent excessive operations."""
      
      def __init__(self, callback: Callable, delay_ms: int = 300):
          """Initialize debounced filter.
          
          Args:
              callback: Function to call after delay
              delay_ms: Delay in milliseconds
          """
          self.callback = callback
          self.delay_ms = delay_ms
          self.timer = QTimer()
          self.timer.setSingleShot(True)
          self.timer.timeout.connect(callback)
      
      def trigger(self):
          """Trigger filter (restarts timer)."""
          self.timer.stop()
          self.timer.start(self.delay_ms)
      
      def cancel(self):
          """Cancel pending filter."""
          self.timer.stop()
  ```
- **Usage**: Use for search/filter inputs
- **Benefits**: Reduces unnecessary operations

### Task 6.6.4: Implement Performance Diagnostics

**What to Build**
- Performance metrics collection
- Performance reporting
- Performance visualization
- Performance recommendations

**Implementation Details**

**6.6.4.1 Performance Metrics Collection**
- **Purpose**: Collect performance data
- **Metrics to Collect**:
  - Operation durations
  - Memory usage
  - CPU usage
  - I/O operations
  - Network operations
- **Implementation**: See PerformanceMonitor above
- **Storage**: Can be logged or stored for analysis

**6.6.4.2 Performance Reporting**
- **Purpose**: Generate performance reports
- **Implementation**:
  ```python
  class PerformanceReporter:
      """Generate performance reports."""
      
      @staticmethod
      def generate_report() -> str:
          """Generate performance report.
          
          Returns:
              Formatted performance report
          """
          summary = PerformanceMonitor.get_summary()
          metrics = PerformanceMonitor.get_metrics()
          
          lines = ["Performance Report", "=" * 60]
          
          lines.append("\nSummary by Operation:")
          for op, stats in summary.items():
              lines.append(f"\n{op}:")
              lines.append(f"  Count: {stats['count']}")
              lines.append(f"  Average: {stats['avg_ms']:.2f}ms")
              lines.append(f"  Min: {stats['min_ms']:.2f}ms")
              lines.append(f"  Max: {stats['max_ms']:.2f}ms")
              lines.append(f"  Total: {stats['total_ms']:.2f}ms")
          
          # Budget violations
          lines.append("\nBudget Violations:")
          violations = [m for m in metrics if not m.get("budget_ok", True)]
          if violations:
              for v in violations:
                  lines.append(f"  {v['operation']}: {v.get('budget_status', 'N/A')}")
          else:
              lines.append("  None")
          
          return "\n".join(lines)
  ```
- **Usage**: Include in diagnostics
- **Benefits**: Helps identify performance issues

## Implementation Checklist

### Documentation Tasks
- [ ] Document performance budgets
- [ ] Document worker usage
- [ ] Document performance monitoring
- [ ] Document optimization guidelines

### Code Analysis Tasks
- [ ] Review all long-running operations
- [ ] Identify UI blocking operations
- [ ] Review table implementations
- [ ] Check for O(n²) operations

### Implementation Tasks (Code)
- [ ] Create worker system
- [ ] Implement progress throttling
- [ ] Implement performance monitoring
- [ ] Optimize table population
- [ ] Add debounced filtering
- [ ] Add performance diagnostics
- [ ] Update all long operations to use workers

### Testing Tasks
- [ ] Test UI responsiveness
- [ ] Test worker cancellation
- [ ] Test performance budgets
- [ ] Test large result sets
- [ ] Test performance monitoring

## Files to Create/Modify

### New Files
1. `SRC/cuepoint/utils/workers.py` - Background worker system
2. `SRC/cuepoint/utils/performance_monitor.py` - Performance monitoring

### Files to Modify
1. `SRC/cuepoint/utils/performance.py` - Enhance existing (if exists)
2. `SRC/cuepoint/ui/widgets/results_view.py` - Optimize table
3. All modules with long-running operations

## Implementation Dependencies

### Prerequisites
- Step 6.2: Logging (logs performance metrics)
- Qt/PySide6 installed
- psutil library (for memory monitoring)

### Enables
- Responsive UI
- Better user experience
- Performance optimization
- Performance monitoring

## Success Criteria

### Functional
- ✅ UI remains responsive during operations
- ✅ Progress updates throttled appropriately
- ✅ Large result sets handled efficiently
- ✅ Performance budgets met
- ✅ Performance metrics collected

### Technical
- ✅ All long operations use workers
- ✅ No UI thread blocking
- ✅ Efficient table population
- ✅ Debounced filtering works
- ✅ Performance monitoring accurate

### User Experience
- ✅ UI never freezes
- ✅ Smooth progress updates
- ✅ Fast table operations
- ✅ Responsive to user input
- ✅ Clear performance feedback

## Next Implementation Steps

After completing Step 6.6:
1. **Step 6.7**: Backups and Safety (ensures data safety)
2. All application features (benefit from performance optimizations)

## Detailed Implementation Guidance

### Performance Best Practices

**UI Responsiveness**:
- Never block UI thread
- Use workers for long operations
- Throttle progress updates
- Use debouncing for user input

**Memory Management**:
- Release resources promptly
- Use efficient data structures
- Avoid memory leaks
- Monitor memory usage

**Algorithm Efficiency**:
- Avoid O(n²) operations
- Use appropriate data structures
- Cache expensive computations
- Batch operations when possible

### Performance Monitoring

**What to Monitor**:
- Operation durations
- Memory usage
- CPU usage
- I/O operations
- Network operations

**When to Monitor**:
- During development
- In production (optional)
- When investigating issues
- For optimization

### Advanced Performance Optimizations

**Memory Optimization**:
- Use generators for large datasets
- Release references promptly
- Use weak references where appropriate
- Monitor memory usage
- Profile memory allocations

**CPU Optimization**:
- Use efficient algorithms
- Cache expensive computations
- Parallelize when possible
- Optimize hot paths
- Profile CPU usage

**I/O Optimization**:
- Batch file operations
- Use async I/O when possible
- Minimize disk seeks
- Cache file reads
- Compress data when appropriate

**UI Optimization**:
- Minimize widget creation
- Reuse widgets when possible
- Use efficient layouts
- Optimize painting operations
- Reduce redraws

### Performance Profiling

**Profiling Tools**:
- cProfile for Python profiling
- memory_profiler for memory profiling
- py-spy for production profiling
- Qt profiler for UI profiling
- System profilers (Instruments, perf)

**Profiling Strategy**:
- Profile during development
- Identify hot paths
- Measure before and after optimization
- Profile realistic workloads
- Monitor in production (optional)

**Profiling Workflow**:
1. Identify performance issue
2. Profile to find bottleneck
3. Optimize bottleneck
4. Measure improvement
5. Verify no regressions

### Performance Testing

**Test Scenarios**:
- Large result sets (1000+ items)
- Many concurrent operations
- Long-running operations
- Memory-intensive operations
- Network-bound operations

**Performance Benchmarks**:
- Startup time
- Operation completion time
- Memory usage
- CPU usage
- UI responsiveness

**Continuous Monitoring**:
- Track performance over time
- Detect performance regressions
- Monitor resource usage
- Alert on performance degradation

### Worker Thread Management

**Thread Pool**:
- Use thread pool for multiple workers
- Limit concurrent workers
- Queue workers when pool full
- Monitor thread pool usage
- Handle thread pool exhaustion

**Worker Lifecycle**:
- Start workers on demand
- Clean up finished workers
- Handle worker cancellation
- Monitor worker status
- Handle worker errors

**Worker Communication**:
- Use signals for thread-safe communication
- Minimize data copying
- Use queues for data transfer
- Avoid shared mutable state
- Use locks when necessary

### Progress Update Optimization

**Update Frequency**:
- Balance update frequency with performance
- Throttle updates appropriately
- Batch multiple updates
- Skip updates if UI not visible
- Use efficient update mechanisms

**Progress Calculation**:
- Calculate progress accurately
- Handle indeterminate progress
- Estimate remaining time
- Show meaningful progress
- Handle progress errors

**Progress UI**:
- Use efficient progress widgets
- Minimize progress widget updates
- Cache progress display
- Use appropriate progress indicators
- Handle progress cancellation

## References

- Main document: `../06_Runtime_Operational_Design.md`
- Qt Threading: https://doc.qt.io/qt-6/threads.html
- Python Profiling: https://docs.python.org/3/library/profile.html
- Performance Best Practices: https://wiki.qt.io/Performance
- Step 6.2: Logging (logs performance metrics)
- Step 6.5: Caching Strategy (improves performance)
