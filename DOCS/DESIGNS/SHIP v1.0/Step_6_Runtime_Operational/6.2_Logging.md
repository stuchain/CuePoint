# Implementation Step 6.2: Logging

## Implementation Overview
**What We're Building**: A comprehensive logging system that provides rotating file logs, structured log levels, console output for development, crash log separation, and logging UI components. This system ensures that CuePoint can be debugged effectively, provides diagnostic information for support, maintains performance through log rotation, and gives users control over log verbosity while protecting sensitive information.

## Implementation Tasks

### Task 6.2.1: Define Logging Architecture

**What to Build**
- Logging configuration system
- Log level management
- Log rotation mechanism
- Log file naming and organization
- Console vs file logging strategy

**Implementation Details**

**6.2.1.1 Logging Configuration Architecture**
- **Purpose**: Centralized logging configuration that supports multiple handlers, levels, and formats
- **Rationale**:
  - Single source of truth for logging behavior
  - Easy to modify logging behavior
  - Supports different configurations for dev vs production
  - Enables runtime log level changes
- **File to Create/Modify**: `SRC/cuepoint/utils/logger.py` (may need to create or enhance existing)
- **Implementation**:
  ```python
  import logging
  import logging.handlers
  from pathlib import Path
  from typing import Optional
  from datetime import datetime
  
  from cuepoint.utils.paths import AppPaths
  from cuepoint.utils.platform import is_dev_build
  from cuepoint.version import get_version, get_build_info
  
  class CuePointLogger:
      """Centralized logging configuration for CuePoint."""
      
      _configured = False
      _log_level = logging.INFO
      
      @staticmethod
      def configure(
          level: Optional[int] = None,
          enable_console: Optional[bool] = None,
          log_file: Optional[Path] = None
      ) -> None:
          """Configure logging system.
          
          Args:
              level: Log level (default: INFO, DEBUG in dev builds)
              enable_console: Enable console logging (default: dev builds only)
              log_file: Log file path (default: logs_dir/cuepoint.log)
          """
          if CuePointLogger._configured:
              return
          
          # Determine log level
          if level is None:
              level = logging.DEBUG if is_dev_build() else logging.INFO
          
          CuePointLogger._log_level = level
          
          # Determine console logging
          if enable_console is None:
              enable_console = is_dev_build()
          
          # Determine log file
          if log_file is None:
              log_file = AppPaths.logs_dir() / "cuepoint.log"
          
          # Get root logger
          root_logger = logging.getLogger()
          root_logger.setLevel(level)
          
          # Clear existing handlers
          root_logger.handlers.clear()
          
          # Create formatters
          file_formatter = logging.Formatter(
              '%(asctime)s [%(levelname)-8s] %(name)s: %(message)s',
              datefmt='%Y-%m-%d %H:%M:%S'
          )
          
          console_formatter = logging.Formatter(
              '[%(levelname)-8s] %(name)s: %(message)s'
          )
          
          # File handler with rotation
          file_handler = CuePointLogger._create_rotating_handler(
              log_file,
              file_formatter,
              level
          )
          root_logger.addHandler(file_handler)
          
          # Console handler (dev builds only)
          if enable_console:
              console_handler = logging.StreamHandler()
              console_handler.setLevel(level)
              console_handler.setFormatter(console_formatter)
              root_logger.addHandler(console_handler)
          
          # Log startup information
          logger = logging.getLogger(__name__)
          logger.info("=" * 60)
          logger.info("CuePoint Starting")
          logger.info("=" * 60)
          
          build_info = get_build_info()
          logger.info(f"Version: {build_info['version']}")
          if build_info.get('build_number'):
              logger.info(f"Build: {build_info['build_number']}")
          if build_info.get('commit_sha'):
              logger.info(f"Commit: {build_info['short_commit_sha']}")
          
          import platform
          logger.info(f"Platform: {platform.system()} {platform.release()}")
          logger.info(f"Python: {platform.python_version()}")
          
          CuePointLogger._configured = True
      
      @staticmethod
      def _create_rotating_handler(
          log_file: Path,
          formatter: logging.Formatter,
          level: int
      ) -> logging.handlers.RotatingFileHandler:
          """Create rotating file handler.
          
          Args:
              log_file: Path to log file
              formatter: Log formatter
              level: Log level
              
          Returns:
              Configured RotatingFileHandler
          """
          # Ensure log directory exists
          log_file.parent.mkdir(parents=True, exist_ok=True)
          
          # Create rotating handler
          # Rotate at 5MB, keep 5 backup files
          handler = logging.handlers.RotatingFileHandler(
              str(log_file),
              maxBytes=5 * 1024 * 1024,  # 5MB
              backupCount=5,
              encoding='utf-8'
          )
          
          handler.setLevel(level)
          handler.setFormatter(formatter)
          
          return handler
      
      @staticmethod
      def set_level(level: int) -> None:
          """Change log level at runtime.
          
          Args:
              level: New log level (logging.DEBUG, INFO, WARNING, ERROR, CRITICAL)
          """
          CuePointLogger._log_level = level
          root_logger = logging.getLogger()
          root_logger.setLevel(level)
          
          # Update all handlers
          for handler in root_logger.handlers:
              handler.setLevel(level)
      
      @staticmethod
      def get_log_file() -> Path:
          """Get current log file path."""
          for handler in logging.getLogger().handlers:
              if isinstance(handler, logging.handlers.RotatingFileHandler):
                  return Path(handler.baseFilename)
          return AppPaths.logs_dir() / "cuepoint.log"
  ```
- **Integration**: Called at application startup before any other logging
- **Configuration**: Can be configured via settings or environment variables
- **Performance**: Minimal overhead, async logging can be added later if needed

**6.2.1.2 Log Level Management**
- **Purpose**: Provide granular control over what gets logged
- **Log Levels**:
  - `DEBUG`: Detailed information for debugging (dev builds only)
  - `INFO`: General informational messages (default)
  - `WARNING`: Warning messages for potential issues
  - `ERROR`: Error messages for failures
  - `CRITICAL`: Critical errors that may cause app failure
- **Default Behavior**:
  - Production: INFO level
  - Development: DEBUG level
  - User can change in settings
- **Implementation**:
  ```python
  class LogLevelManager:
      """Manage log levels and filtering."""
      
      # Log level names for UI
      LEVEL_NAMES = {
          logging.DEBUG: "Debug",
          logging.INFO: "Info",
          logging.WARNING: "Warning",
          logging.ERROR: "Error",
          logging.CRITICAL: "Critical",
      }
      
      @staticmethod
      def get_level_name(level: int) -> str:
          """Get human-readable level name."""
          return LogLevelManager.LEVEL_NAMES.get(level, "Unknown")
      
      @staticmethod
      def set_level_from_string(level_name: str) -> None:
          """Set log level from string name.
          
          Args:
              level_name: "debug", "info", "warning", "error", "critical"
          """
          level_map = {
              "debug": logging.DEBUG,
              "info": logging.INFO,
              "warning": logging.WARNING,
              "error": logging.ERROR,
              "critical": logging.CRITICAL,
          }
          
          level = level_map.get(level_name.lower(), logging.INFO)
          CuePointLogger.set_level(level)
      
      @staticmethod
      def get_current_level() -> int:
          """Get current log level."""
          return logging.getLogger().level
  ```
- **User Control**: Should be accessible via Settings dialog
- **Persistence**: Log level preference should be saved

**6.2.1.3 Log Rotation Specification**
- **Purpose**: Prevent log files from growing indefinitely
- **Rotation Policy**:
  - File: `cuepoint.log`
  - Rotate at: 5MB
  - Keep: 5 backup files (`cuepoint.log.1` through `cuepoint.log.5`)
  - Oldest file deleted when limit reached
- **Implementation**: Uses Python's `RotatingFileHandler` (shown above)
- **Benefits**:
  - Prevents disk space issues
  - Maintains recent history
  - Automatic cleanup
- **Configuration**: Can be made configurable if needed

**6.2.1.4 Crash Log Separation**
- **Purpose**: Separate crash logs from regular logs for easier analysis
- **Crash Log Format**: `crash-YYYYMMDD-HHMMSS.log`
- **Implementation**:
  ```python
  class CrashLogger:
      """Handle crash-specific logging."""
      
      @staticmethod
      def create_crash_log() -> Path:
          """Create a new crash log file.
          
          Returns:
              Path to crash log file
          """
          crash_dir = AppPaths.logs_dir() / "crashes"
          crash_dir.mkdir(parents=True, exist_ok=True)
          
          timestamp = datetime.now().strftime("%Y%m%d-%H%M%S")
          crash_log = crash_dir / f"crash-{timestamp}.log"
          
          return crash_log
      
      @staticmethod
      def write_crash_info(crash_log: Path, exception: Exception, traceback_str: str) -> None:
          """Write crash information to crash log.
          
          Args:
              crash_log: Path to crash log file
              exception: Exception that caused crash
              traceback_str: Full traceback string
          """
          with open(crash_log, 'w', encoding='utf-8') as f:
              f.write("=" * 60 + "\n")
              f.write("CuePoint Crash Report\n")
              f.write("=" * 60 + "\n")
              f.write(f"Timestamp: {datetime.now().isoformat()}\n")
              f.write(f"Exception: {type(exception).__name__}\n")
              f.write(f"Message: {str(exception)}\n")
              f.write("\n")
              f.write("Traceback:\n")
              f.write(traceback_str)
              f.write("\n")
              
              # Add recent log entries
              f.write("\n" + "=" * 60 + "\n")
              f.write("Recent Log Entries (last 200 lines)\n")
              f.write("=" * 60 + "\n")
              
              recent_logs = CrashLogger._get_recent_logs(200)
              f.write(recent_logs)
      
      @staticmethod
      def _get_recent_logs(lines: int = 200) -> str:
          """Get recent log entries from main log file.
          
          Args:
              lines: Number of lines to retrieve
              
          Returns:
              Recent log entries as string
          """
          log_file = CuePointLogger.get_log_file()
          
          if not log_file.exists():
              return "No log file found.\n"
          
          try:
              # Read last N lines
              with open(log_file, 'r', encoding='utf-8') as f:
                  all_lines = f.readlines()
                  recent = all_lines[-lines:] if len(all_lines) > lines else all_lines
                  return "".join(recent)
          except Exception as e:
              return f"Error reading log file: {e}\n"
  ```
- **Integration**: Used by crash handler (Step 6.3)
- **Location**: `logs/crashes/` subdirectory
- **Retention**: Crash logs kept separately, can be cleaned up manually or automatically

### Task 6.2.2: Implement Logging Content Requirements

**What to Build**
- Logging content guidelines
- Sensitive information filtering
- Context information inclusion
- Timing information logging
- Performance metrics logging

**Implementation Details**

**6.2.2.1 Logging Content Guidelines**
- **What to Log**:
  - Application version and build info (startup)
  - OS version and platform info (startup)
  - Key settings (non-sensitive) (startup)
  - User actions (high-level, not detailed)
  - Processing operations (start, progress, completion)
  - Network requests (URLs, status codes, timing)
  - Errors and exceptions (full traceback)
  - Performance metrics (timing, counts)
- **What NOT to Log**:
  - User tokens or passwords (never)
  - Full HTML dumps (unless explicitly enabled)
  - Personal information (user names, file paths with personal data)
  - API keys or secrets
  - Credit card numbers or payment info
- **Implementation**:
  ```python
  class SafeLogger:
      """Logger with sensitive information filtering."""
      
      # Patterns to redact
      SENSITIVE_PATTERNS = [
          r'password["\']?\s*[:=]\s*["\']?([^"\']+)',
          r'token["\']?\s*[:=]\s*["\']?([^"\']+)',
          r'api[_-]?key["\']?\s*[:=]\s*["\']?([^"\']+)',
          r'secret["\']?\s*[:=]\s*["\']?([^"\']+)',
      ]
      
      @staticmethod
      def sanitize_message(message: str) -> str:
          """Remove sensitive information from log message.
          
          Args:
              message: Original message
              
          Returns:
              Sanitized message
          """
          import re
          
          sanitized = message
          for pattern in SafeLogger.SENSITIVE_PATTERNS:
              sanitized = re.sub(
                  pattern,
                  lambda m: m.group(0).split('=')[0] + '=***REDACTED***',
                  sanitized,
                  flags=re.IGNORECASE
              )
          
          return sanitized
      
      @staticmethod
      def log_safe(logger: logging.Logger, level: int, message: str, *args, **kwargs):
          """Log message with sensitive information filtering.
          
          Args:
              logger: Logger instance
              level: Log level
              message: Message to log
              *args, **kwargs: Additional arguments
          """
          sanitized = SafeLogger.sanitize_message(str(message))
          logger.log(level, sanitized, *args, **kwargs)
  ```
- **Enforcement**: Should be used for all user-facing logging
- **Testing**: Should test that sensitive patterns are properly redacted

**6.2.2.2 Context Information Logging**
- **Purpose**: Include useful context in log messages
- **Context to Include**:
  - Function/method name
  - File and line number (in DEBUG mode)
  - User ID or session ID (if applicable)
  - Operation context (processing mode, file being processed)
  - Thread/process ID (for debugging concurrency issues)
- **Implementation**:
  ```python
  import functools
  import inspect
  
  def log_context(func):
      """Decorator to add context to log messages."""
      @functools.wraps(func)
      def wrapper(*args, **kwargs):
          logger = logging.getLogger(func.__module__)
          
          # Log function entry (DEBUG level)
          logger.debug(
              f"Entering {func.__name__} "
              f"(file: {inspect.getfile(func)}, line: {inspect.getsourcelines(func)[1]})"
          )
          
          try:
              result = func(*args, **kwargs)
              logger.debug(f"Exiting {func.__name__} (success)")
              return result
          except Exception as e:
              logger.error(
                  f"Error in {func.__name__}: {e}",
                  exc_info=True
              )
              raise
      
      return wrapper
  ```
- **Usage**: Can be applied to critical functions
- **Performance**: Minimal overhead, can be disabled in production

**6.2.2.3 Timing Information Logging**
- **Purpose**: Log timing information for performance analysis
- **What to Log**:
  - Operation start/end times
  - Duration of operations
  - Network request timing
  - Processing time per item
  - Total processing time
- **Implementation**:
  ```python
  import time
  from contextlib import contextmanager
  
  @contextmanager
  def log_timing(operation_name: str, logger: Optional[logging.Logger] = None):
      """Context manager to log operation timing.
      
      Usage:
          with log_timing("process_file"):
              # operation code
      
      Args:
          operation_name: Name of operation
          logger: Logger instance (default: root logger)
      """
      if logger is None:
          logger = logging.getLogger()
      
      start_time = time.time()
      logger.info(f"Starting {operation_name}")
      
      try:
          yield
          duration = time.time() - start_time
          logger.info(f"Completed {operation_name} in {duration:.2f}s")
      except Exception as e:
          duration = time.time() - start_time
          logger.error(f"Failed {operation_name} after {duration:.2f}s: {e}")
          raise
  ```
- **Usage**: Wrap long-running operations
- **Benefits**: Helps identify performance bottlenecks

### Task 6.2.3: Implement Logging UI Components

**What to Build**
- Log viewer widget
- Log level selector
- "Open Logs Folder" functionality
- "Copy diagnostic info" functionality
- Log filtering and search

**Implementation Details**

**6.2.3.1 Log Viewer Widget**
- **Purpose**: Display logs in UI for debugging
- **File to Create/Modify**: `SRC/cuepoint/ui/widgets/log_viewer.py` (may already exist)
- **Features**:
  - Real-time log display
  - Auto-scroll to latest
  - Log level filtering
  - Search functionality
  - Copy selected text
  - Clear log display
- **Implementation**:
  ```python
  from PySide6.QtWidgets import (
      QWidget, QVBoxLayout, QTextEdit, QHBoxLayout,
      QPushButton, QComboBox, QLineEdit, QLabel
  )
  from PySide6.QtCore import Qt, QTimer, Signal
  import logging
  from pathlib import Path
  
  class LogViewerWidget(QWidget):
      """Widget for viewing application logs."""
      
      def __init__(self, parent=None):
          super().__init__(parent)
          self._setup_ui()
          self._setup_log_monitoring()
      
      def _setup_ui(self):
          """Setup UI components."""
          layout = QVBoxLayout(self)
          
          # Controls
          controls = QHBoxLayout()
          
          # Log level filter
          controls.addWidget(QLabel("Level:"))
          self.level_filter = QComboBox()
          self.level_filter.addItems(["All", "Debug", "Info", "Warning", "Error", "Critical"])
          self.level_filter.currentTextChanged.connect(self._filter_logs)
          controls.addWidget(self.level_filter)
          
          # Search
          controls.addWidget(QLabel("Search:"))
          self.search_box = QLineEdit()
          self.search_box.setPlaceholderText("Search logs...")
          self.search_box.textChanged.connect(self._filter_logs)
          controls.addWidget(self.search_box)
          
          # Buttons
          self.clear_btn = QPushButton("Clear Display")
          self.clear_btn.clicked.connect(self._clear_display)
          controls.addWidget(self.clear_btn)
          
          self.refresh_btn = QPushButton("Refresh")
          self.refresh_btn.clicked.connect(self._refresh_logs)
          controls.addWidget(self.refresh_btn)
          
          controls.addStretch()
          layout.addLayout(controls)
          
          # Log display
          self.log_display = QTextEdit()
          self.log_display.setReadOnly(True)
          self.log_display.setFontFamily("Courier")
          self.log_display.setFontPointSize(9)
          layout.addWidget(self.log_display)
          
          # Auto-scroll checkbox
          self.auto_scroll = True
          auto_scroll_btn = QPushButton("Auto-scroll: ON")
          auto_scroll_btn.setCheckable(True)
          auto_scroll_btn.setChecked(True)
          auto_scroll_btn.toggled.connect(
              lambda checked: setattr(self, 'auto_scroll', checked) or
                              auto_scroll_btn.setText(f"Auto-scroll: {'ON' if checked else 'OFF'}")
          )
          layout.addWidget(auto_scroll_btn)
      
      def _setup_log_monitoring(self):
          """Setup log file monitoring."""
          self.log_file = CuePointLogger.get_log_file()
          self.last_position = 0
          
          # Refresh timer
          self.refresh_timer = QTimer()
          self.refresh_timer.timeout.connect(self._refresh_logs)
          self.refresh_timer.start(1000)  # Refresh every second
          
          # Initial load
          self._refresh_logs()
      
      def _refresh_logs(self):
          """Refresh log display from file."""
          if not self.log_file.exists():
              return
          
          try:
              with open(self.log_file, 'r', encoding='utf-8') as f:
                  f.seek(self.last_position)
                  new_lines = f.readlines()
                  self.last_position = f.tell()
                  
                  if new_lines:
                      self._append_logs(new_lines)
          except Exception as e:
              # Log error but don't crash
              pass
      
      def _append_logs(self, lines: list):
          """Append log lines to display."""
          for line in lines:
              if self._should_display_line(line):
                  self.log_display.append(line.rstrip())
          
          # Auto-scroll
          if self.auto_scroll:
              scrollbar = self.log_display.verticalScrollBar()
              scrollbar.setValue(scrollbar.maximum())
      
      def _should_display_line(self, line: str) -> bool:
          """Check if line should be displayed based on filters."""
          # Level filter
          level_filter = self.level_filter.currentText()
          if level_filter != "All":
              if f"[{level_filter.upper()}" not in line:
                  return False
          
          # Search filter
          search_text = self.search_box.text()
          if search_text and search_text.lower() not in line.lower():
              return False
          
          return True
      
      def _filter_logs(self):
          """Re-filter and refresh log display."""
          self.log_display.clear()
          self.last_position = 0
          self._refresh_logs()
      
      def _clear_display(self):
          """Clear log display (does not clear file)."""
          self.log_display.clear()
  ```
- **Integration**: Can be added to Settings dialog or separate Diagnostics window
- **Performance**: Uses file monitoring to avoid loading entire log file

**6.2.3.2 Log Folder Access**
- **Purpose**: Allow users to open logs folder in file manager
- **Implementation**:
  ```python
  from PySide6.QtCore import QUrl
  from PySide6.QtGui import QDesktopServices
  from cuepoint.utils.paths import AppPaths
  
  def open_logs_folder():
      """Open logs folder in file manager."""
      logs_dir = AppPaths.logs_dir()
      QDesktopServices.openUrl(QUrl.fromLocalFile(str(logs_dir)))
  ```
- **UI Integration**: Button in Settings or Diagnostics dialog
- **Platform Support**: Works on macOS, Windows, Linux

**6.2.3.3 Diagnostic Info Copy**
- **Purpose**: Copy diagnostic information to clipboard
- **Implementation**:
  ```python
  from PySide6.QtWidgets import QApplication
  from PySide6.QtGui import QClipboard
  
  def copy_diagnostic_info():
      """Copy diagnostic information to clipboard."""
      from cuepoint.utils.diagnostics import collect_diagnostics
      from cuepoint.utils.path_diagnostics import PathDiagnostics
      
      diag = collect_diagnostics()
      path_diag = PathDiagnostics.format_diagnostics()
      
      info = f"""CuePoint Diagnostic Information
{'=' * 60}

{path_diag}

{diag}

Recent Logs:
{'-' * 60}
{get_recent_logs(50)}
"""
      
      clipboard = QApplication.clipboard()
      clipboard.setText(info)
  ```
- **UI Integration**: Button in Settings or Diagnostics dialog
- **Content**: Should include paths, system info, recent logs

## Implementation Checklist

### Documentation Tasks
- [ ] Document logging configuration
- [ ] Document log file locations
- [ ] Document log levels and when to use each
- [ ] Document sensitive information policies

### Code Analysis Tasks
- [ ] Review existing logging implementation
- [ ] Identify all logging calls
- [ ] Check for sensitive information leaks
- [ ] Review log file sizes and rotation

### Implementation Tasks (Code)
- [ ] Create/enhance CuePointLogger class
- [ ] Implement log rotation
- [ ] Implement crash log separation
- [ ] Implement sensitive information filtering
- [ ] Create log viewer widget
- [ ] Add logging UI to settings
- [ ] Add diagnostic info copy functionality
- [ ] Add log level control to settings

### Testing Tasks
- [ ] Test log rotation
- [ ] Test log level changes
- [ ] Test sensitive information filtering
- [ ] Test log viewer widget
- [ ] Test crash log creation
- [ ] Test diagnostic info collection

## Files to Create/Modify

### New Files
1. `SRC/cuepoint/utils/logger.py` - Main logging configuration (if doesn't exist)
2. `SRC/cuepoint/utils/crash_logger.py` - Crash log handling (if separate)

### Files to Modify
1. `SRC/cuepoint/utils/logger_helper.py` - Enhance existing logging (if exists)
2. `SRC/cuepoint/ui/widgets/log_viewer.py` - Enhance log viewer (if exists)
3. `SRC/cuepoint/ui/dialogs/settings_dialog.py` - Add logging controls
4. `SRC/gui_app.py` - Add logging initialization
5. `SRC/cuepoint/utils/diagnostics.py` - Add log collection to diagnostics

## Implementation Dependencies

### Prerequisites
- Step 6.1: File System Locations (needs logs directory)
- Qt/PySide6 installed
- Python logging module

### Enables
- Step 6.3: Crash Handling (uses logging for crash reports)
- All application components (use logging for debugging)
- Support and diagnostics (logs provide diagnostic info)

## Success Criteria

### Functional
- ✅ Logs written to correct location
- ✅ Log rotation works correctly
- ✅ Log levels configurable
- ✅ Console logging in dev builds only
- ✅ Crash logs separated
- ✅ Sensitive information filtered
- ✅ Log viewer works
- ✅ Diagnostic info copy works

### Technical
- ✅ Logging configured at startup
- ✅ Log rotation prevents disk space issues
- ✅ Log levels changeable at runtime
- ✅ Performance impact minimal
- ✅ No sensitive information in logs

### User Experience
- ✅ Users can view logs
- ✅ Users can open logs folder
- ✅ Users can copy diagnostic info
- ✅ Log level adjustable in settings
- ✅ Clear error messages if logging fails

## Next Implementation Steps

After completing Step 6.2:
1. **Step 6.3**: Crash Handling (uses logging infrastructure)
2. **Step 6.4**: Networking Reliability (logs network operations)
3. **Step 6.6**: Performance (logs performance metrics)

## Detailed Implementation Guidance

### Logging Best Practices

**Startup Logging**:
- Log application version and build info
- Log platform information
- Log configuration (non-sensitive)
- Log any initialization errors

**Operation Logging**:
- Log operation start and completion
- Log errors with full context
- Log timing for performance analysis
- Log user actions (high-level)

**Error Logging**:
- Always include full traceback
- Include context (what user was doing)
- Include relevant state information
- Never log sensitive information

### Performance Considerations

**Logging Overhead**:
- Use appropriate log levels
- Avoid logging in tight loops
- Use lazy evaluation for expensive operations
- Consider async logging for high-volume scenarios

**Log File Management**:
- Rotate logs regularly
- Clean up old crash logs
- Monitor log file sizes
- Compress old logs if needed

### Security Considerations

**Sensitive Information**:
- Never log passwords or tokens
- Redact API keys and secrets
- Be careful with file paths (may contain user names)
- Review logs before sharing

**Log File Access**:
- Logs may contain sensitive information
- Consider log file permissions
- Warn users before sharing logs
- Provide option to sanitize logs

## References

- Main document: `../06_Runtime_Operational_Design.md`
- Python Logging: https://docs.python.org/3/library/logging.html
- Qt Logging: https://doc.qt.io/qt-6/qtglobal.html#qDebug
- Step 6.1: File System Locations (provides logs directory)



